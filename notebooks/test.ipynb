{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 設定 OpenAI API Key (請在環境變數中設定或替換為您的實際 API Key)\n",
    "# os.environ['OPENAI_API_KEY'] = 'your-openai-api-key-here'\n",
    "# 或者從環境變數讀取：\n",
    "# os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[0;32m      2\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI()\n\u001b[1;32m----> 4\u001b[0m completion \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m  \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m  \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCompose a poem that explains the concept of recursion in programming.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m  \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage)\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\openai\\_utils\\_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\openai\\resources\\chat\\completions.py:829\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    826\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    827\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    828\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m--> 829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\openai\\_base_client.py:1278\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1266\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1273\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1274\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1275\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1276\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1277\u001b[0m     )\n\u001b[1;32m-> 1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\openai\\_base_client.py:955\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    952\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    953\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 955\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\openai\\_base_client.py:1044\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1043\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1044\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1045\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1046\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1049\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1050\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\openai\\_base_client.py:1093\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1089\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1090\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1093\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1094\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1098\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\openai\\_base_client.py:1044\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1043\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1044\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1045\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1046\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1049\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1050\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\openai\\_base_client.py:1093\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1089\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1090\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1093\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1094\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1098\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages\\openai\\_base_client.py:1059\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1056\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1058\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1059\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1062\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1063\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1067\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1068\u001b[0m )\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# 使用環境變數中的 API Key 初始化客戶端\n",
    "# 確保您已經設定了 OPENAI_API_KEY 環境變數\n",
    "client = OpenAI()  # 會自動從環境變數 OPENAI_API_KEY 讀取\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (3.5.0)\n",
      "Requirement already satisfied: dataclasses in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: sentencepiece==0.1.91 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from transformers) (0.1.91)\n",
      "Requirement already satisfied: tokenizers==0.9.3 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from transformers) (0.9.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: requests in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from transformers) (2.24.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from transformers) (4.43.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from transformers) (1.16.4)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from transformers) (0.0.53)\n",
      "Requirement already satisfied: filelock in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from transformers) (3.4.1)\n",
      "Requirement already satisfied: protobuf in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from transformers) (3.19.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from packaging->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: click in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from sacremoses->transformers) (8.0.4)\n",
      "Requirement already satisfied: six in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from sacremoses->transformers) (1.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from click->sacremoses->transformers) (0.4.4)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from click->sacremoses->transformers) (4.8.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from importlib-metadata->click->sacremoses->transformers) (4.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from importlib-metadata->click->sacremoses->transformers) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 665/665 [00:00<00:00, 625kB/s]\n",
      "Downloading: 100%|██████████| 548M/548M [01:20<00:00, 6.77MB/s] \n",
      "Downloading: 100%|██████████| 1.04M/1.04M [00:01<00:00, 990kB/s]\n",
      "Downloading: 100%|██████████| 456k/456k [00:00<00:00, 808kB/s] \n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose a poem that explains the concept of recursion in programming.\n",
      "\n",
      "The following example shows how to write a recursive recursive function that takes a list of integers and returns a list of integers.\n",
      "\n",
      "def rec_list ( x, y ): return x + y return x + y\n",
      "\n",
      "The recursive function rec_list ( x, y ) returns a list of integers.\n",
      "\n",
      "def rec_list ( x, y ): return x + y return x + y\n",
      "\n",
      "The\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# 加載預訓練模型和 tokenizer\n",
    "model_name = \"gpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 定義輸入文本\n",
    "input_text = \"Compose a poem that explains the concept of recursion in programming.\"\n",
    "\n",
    "# 編碼輸入文本\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "\n",
    "# 生成文本\n",
    "output = model.generate(input_ids, max_length=100, num_return_sequences=1)\n",
    "\n",
    "# 解碼並輸出生成的文本\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading config.json: 100%|██████████| 1.46k/1.46k [00:00<?, ?B/s]\n",
      "Downloading model.safetensors:  22%|██▏       | 2.36G/10.7G [07:04<22:29, 6.16MB/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 加載預訓練模型和 tokenizer\u001b[39;00m\n\u001b[0;32m      4\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEleutherAI/gpt-neo-2.7B\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mGPTNeoForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m GPT2Tokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# 定義輸入文本\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages\\transformers\\modeling_utils.py:2494\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   2479\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2480\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m   2481\u001b[0m     cached_file_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   2482\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m: cache_dir,\n\u001b[0;32m   2483\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforce_download\u001b[39m\u001b[38;5;124m\"\u001b[39m: force_download,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2492\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m: commit_hash,\n\u001b[0;32m   2493\u001b[0m     }\n\u001b[1;32m-> 2494\u001b[0m     resolved_archive_file \u001b[38;5;241m=\u001b[39m cached_file(pretrained_model_name_or_path, filename, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcached_file_kwargs)\n\u001b[0;32m   2496\u001b[0m     \u001b[38;5;66;03m# Since we set _raise_exceptions_for_missing_entries=False, we don't get an exception but a None\u001b[39;00m\n\u001b[0;32m   2497\u001b[0m     \u001b[38;5;66;03m# result when internet is up, the repo and revision exist, but the file does not.\u001b[39;00m\n\u001b[0;32m   2498\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolved_archive_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m filename \u001b[38;5;241m==\u001b[39m _add_variant(SAFE_WEIGHTS_NAME, variant):\n\u001b[0;32m   2499\u001b[0m         \u001b[38;5;66;03m# Maybe the checkpoint is sharded, we try to grab the index name in this case.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages\\transformers\\utils\\hub.py:417\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[0;32m    414\u001b[0m user_agent \u001b[38;5;241m=\u001b[39m http_user_agent(user_agent)\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    416\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 417\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError:\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    434\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    435\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    436\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpass a token having permission to this repo with `use_auth_token` or log in with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    437\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`huggingface-cli login` and pass `use_auth_token=True`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    438\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages\\huggingface_hub\\file_download.py:1364\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[0;32m   1361\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m temp_file_manager() \u001b[38;5;28;01mas\u001b[39;00m temp_file:\n\u001b[0;32m   1362\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdownloading \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, temp_file\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m-> 1364\u001b[0m     \u001b[43mhttp_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1365\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1366\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemp_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1367\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1368\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1371\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m local_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1374\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStoring \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in cache at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mblob_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages\\huggingface_hub\\file_download.py:541\u001b[0m, in \u001b[0;36mhttp_get\u001b[1;34m(url, temp_file, proxies, resume_size, headers, timeout, max_retries, expected_size)\u001b[0m\n\u001b[0;32m    531\u001b[0m     displayed_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(…)\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdisplayed_name[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m20\u001b[39m:]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m progress \u001b[38;5;241m=\u001b[39m tqdm(\n\u001b[0;32m    534\u001b[0m     unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    535\u001b[0m     unit_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    539\u001b[0m     disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m(logger\u001b[38;5;241m.\u001b[39mgetEffectiveLevel() \u001b[38;5;241m==\u001b[39m logging\u001b[38;5;241m.\u001b[39mNOTSET),\n\u001b[0;32m    540\u001b[0m )\n\u001b[1;32m--> 541\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m r\u001b[38;5;241m.\u001b[39miter_content(chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m):\n\u001b[0;32m    542\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunk:  \u001b[38;5;66;03m# filter out keep-alive new chunks\u001b[39;00m\n\u001b[0;32m    543\u001b[0m         progress\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(chunk))\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages\\requests\\models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    815\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 816\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    817\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages\\urllib3\\response.py:628\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    626\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp):\n\u001b[1;32m--> 628\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    630\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[0;32m    631\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages\\urllib3\\response.py:567\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    564\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[1;32m--> 567\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    569\u001b[0m         flush_decoder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages\\urllib3\\response.py:533\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m buffer\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    532\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[1;32m--> 533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\http\\client.py:465\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[0;32m    464\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[1;32m--> 465\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1271\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1272\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1273\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1129\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1131\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n",
    "\n",
    "# 加載預訓練模型和 tokenizer\n",
    "model_name = \"EleutherAI/gpt-neo-2.7B\"\n",
    "model = GPTNeoForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 定義輸入文本\n",
    "input_text = \"Compose a poem that explains the concept of recursion in programming.\"\n",
    "\n",
    "# 編碼輸入文本\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "\n",
    "# 生成文本\n",
    "output = model.generate(input_ids, max_length=100, num_return_sequences=1)\n",
    "\n",
    "# 解碼並輸出生成的文本\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (3.5.0)\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\n",
      "Requirement already satisfied: tokenizers==0.9.3 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from transformers) (0.9.3)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from transformers) (0.0.53)\n",
      "Requirement already satisfied: protobuf in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from transformers) (3.19.6)\n",
      "Requirement already satisfied: dataclasses in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from transformers) (2023.6.3)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from transformers) (1.16.4)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script tqdm.exe is installed in 'c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script f2py.exe is installed in 'c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] 存取被拒。: 'c:\\\\users\\\\johnn\\\\anaconda3\\\\envs\\\\fomc_new\\\\lib\\\\site-packages\\\\~~mpy\\\\.libs\\\\libopenblas.TXA6YQSD3GCQQC22GEQ54J2UDCXDXHWN.gfortran-win_amd64.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: filelock in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from transformers) (3.4.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from transformers) (4.43.0)\n",
      "Requirement already satisfied: sentencepiece==0.1.91 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from transformers) (0.1.91)\n",
      "Requirement already satisfied: requests in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from transformers) (2.24.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from datasets) (0.25.0)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.12.2-py36-none-any.whl (106 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.19.5-cp36-cp36m-win_amd64.whl (13.2 MB)\n",
      "Collecting tqdm>=4.27\n",
      "  Using cached tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "Collecting pyarrow>=6.0.0\n",
      "  Downloading pyarrow-6.0.1-cp36-cp36m-win_amd64.whl (15.4 MB)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.2.0-cp36-cp36m-win_amd64.whl (42 kB)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from datasets) (4.8.1)\n",
      "Collecting dill<0.3.6\n",
      "  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.6-cp36-cp36m-win_amd64.whl (342 kB)\n",
      "Collecting huggingface-hub<1.0.0,>=0.1.0\n",
      "  Using cached huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
      "Collecting responses<0.19\n",
      "  Downloading responses-0.17.0-py2.py3-none-any.whl (38 kB)\n",
      "Collecting fsspec[http]>=2021.11.1\n",
      "  Downloading fsspec-2022.1.0-py3-none-any.whl (133 kB)\n",
      "Collecting pyyaml\n",
      "  Downloading PyYAML-6.0.1-cp36-cp36m-win_amd64.whl (153 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from packaging->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: six in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from responses<0.19->datasets) (1.12.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from tqdm>=4.27->transformers) (5.4.0)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from aiohttp->datasets) (2.0.12)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp36-cp36m-win_amd64.whl (121 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.2.0-cp36-cp36m-win_amd64.whl (83 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-5.2.0-cp36-cp36m-win_amd64.whl (45 kB)\n",
      "Collecting asynctest==0.13.0\n",
      "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
      "Collecting idna-ssl>=1.0\n",
      "  Downloading idna-ssl-1.1.0.tar.gz (3.4 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from importlib-metadata->datasets) (3.6.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: click in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from sacremoses->transformers) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from sacremoses->transformers) (1.1.1)\n",
      "Building wheels for collected packages: idna-ssl\n",
      "  Building wheel for idna-ssl (setup.py): started\n",
      "  Building wheel for idna-ssl (setup.py): finished with status 'done'\n",
      "  Created wheel for idna-ssl: filename=idna_ssl-1.1.0-py3-none-any.whl size=3178 sha256=29e655155de69c4fdc528b8a0eb6c52a3dae89b1f8c91583058aad17a3af92f2\n",
      "  Stored in directory: c:\\users\\johnn\\appdata\\local\\pip\\cache\\wheels\\6a\\f5\\9c\\f8331a854f7a8739cf0e74c13854e4dd7b1af11b04fe1dde13\n",
      "Successfully built idna-ssl\n",
      "Installing collected packages: multidict, frozenlist, yarl, idna-ssl, asynctest, async-timeout, aiosignal, tqdm, pyyaml, numpy, fsspec, dill, aiohttp, xxhash, responses, pyarrow, multiprocess, huggingface-hub, datasets\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.43.0\n",
      "    Uninstalling tqdm-4.43.0:\n",
      "      Successfully uninstalled tqdm-4.43.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.16.4\n",
      "    Uninstalling numpy-1.16.4:\n",
      "      Successfully uninstalled numpy-1.16.4\n"
     ]
    }
   ],
   "source": [
    "pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 4.60k/4.60k [00:00<00:00, 4.53MB/s]\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "401 Client Error: Unauthorized for url: https://huggingface.co/facebook/rag-sequence-nq%5Cquestion_encoder_tokenizer/resolve/main/vocab.txt",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-534fe00cccec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# 加載 RAG 模型和 tokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRagTokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"facebook/rag-sequence-nq\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mretriever\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRagRetriever\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"facebook/rag-sequence-nq\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"exact\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_dummy_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRagSequenceForGeneration\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"facebook/rag-sequence-nq\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretriever\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretriever\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages\\transformers\\tokenization_rag.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mquestion_encoder_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"question_encoder_tokenizer\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mgenerator_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"generator_tokenizer\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mquestion_encoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquestion_encoder_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquestion_encoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[0mgenerator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquestion_encoder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquestion_encoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages\\transformers\\tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    339\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer_class_fast\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer_class_py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m         raise ValueError(\n",
      "\u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1634\u001b[0m                         \u001b[0mresolved_vocab_files\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfile_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1635\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1636\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1638\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_file_name\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfull_file_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresolved_vocab_files\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1627\u001b[0m                         \u001b[0mproxies\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1628\u001b[0m                         \u001b[0mresume_download\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_download\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1629\u001b[1;33m                         \u001b[0mlocal_files_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1630\u001b[0m                     )\n\u001b[0;32m   1631\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages\\transformers\\file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[1;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, local_files_only)\u001b[0m\n\u001b[0;32m    953\u001b[0m             \u001b[0mresume_download\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_download\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m             \u001b[0muser_agent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muser_agent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 955\u001b[1;33m             \u001b[0mlocal_files_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    956\u001b[0m         )\n\u001b[0;32m    957\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages\\transformers\\file_utils.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[1;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, local_files_only)\u001b[0m\n\u001b[0;32m   1074\u001b[0m             \u001b[0mheaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"user-agent\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mhttp_user_agent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_agent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1075\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_redirects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1076\u001b[1;33m             \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1077\u001b[0m             \u001b[0metag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"X-Linked-Etag\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ETag\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1078\u001b[0m             \u001b[1;31m# We favor a custom header indicating the etag of the linked resource, and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    940\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 941\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    942\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    943\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/facebook/rag-sequence-nq%5Cquestion_encoder_tokenizer/resolve/main/vocab.txt"
     ]
    }
   ],
   "source": [
    "from transformers import RagTokenizer, RagRetriever, RagSequenceForGeneration\n",
    "\n",
    "# # 安裝所需的庫\n",
    "# !pip install datasets faiss-cpu\n",
    "\n",
    "# 加載 RAG 模型和 tokenizer\n",
    "tokenizer = RagTokenizer.from_pretrained(\"facebook/rag-sequence-nq\")\n",
    "retriever = RagRetriever.from_pretrained(\"facebook/rag-sequence-nq\", index_name=\"exact\", use_dummy_dataset=True)\n",
    "model = RagSequenceForGeneration.from_pretrained(\"facebook/rag-sequence-nq\", retriever=retriever)\n",
    "\n",
    "# 定義輸入文本\n",
    "input_text = \"Explain the concept of recursion in programming.\"\n",
    "\n",
    "# 編碼輸入文本\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\")[\"input_ids\"]\n",
    "\n",
    "# 生成文本\n",
    "generated_ids = model.generate(input_ids, num_beams=2, max_length=100, early_stopping=True)\n",
    "generated_text = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "# 輸出生成的文本\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 100, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent1 generated: Explain the why woman is hot.\n",
      "\n",
      "The reason why women are hot is because they are hot.\n",
      "\n",
      "The reason why women are hot is because they are hot.\n",
      "\n",
      "The reason why women are hot is because they are hot.\n",
      "\n",
      "The reason why women are hot is because they are hot.\n",
      "\n",
      "The reason why women are hot is because they are hot.\n",
      "\n",
      "The reason why women are hot is because they are hot.\n",
      "\n",
      "The reason why women are hot\n",
      "Agent2 generated: Explain the why woman is hot.\n",
      "\n",
      "The reason why women are hot is because they are hot.\n",
      "\n",
      "The reason why women are hot is because they are hot.\n",
      "\n",
      "The reason why women are hot is because they are hot.\n",
      "\n",
      "The reason why women are hot is because they are hot.\n",
      "\n",
      "The reason why women are hot is because they are hot.\n",
      "\n",
      "The reason why women are hot is because they are hot.\n",
      "\n",
      "The reason why women are hot is\n",
      "Final generated text: Explain the why woman is hot.\n",
      "\n",
      "The reason why women are hot is because they are hot.\n",
      "\n",
      "The reason why women are hot is because they are hot.\n",
      "\n",
      "The reason why women are hot is because they are hot.\n",
      "\n",
      "The reason why women are hot is because they are hot.\n",
      "\n",
      "The reason why women are hot is because they are hot.\n",
      "\n",
      "The reason why women are hot is because they are hot.\n",
      "\n",
      "The reason why women are hot is\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "# 加載預訓練模型和 tokenizer\n",
    "model_name = \"gpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 定義多代理系統\n",
    "class Agent:\n",
    "    def __init__(self, name, model, tokenizer):\n",
    "        self.name = name\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def generate_text(self, prompt, max_length=100):\n",
    "        input_ids = self.tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "        output = self.model.generate(input_ids, max_length=max_length, num_return_sequences=1)\n",
    "        generated_text = self.tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        return generated_text\n",
    "\n",
    "# 創建代理\n",
    "agent1 = Agent(\"Agent1\", model, tokenizer)\n",
    "agent2 = Agent(\"Agent2\", model, tokenizer)\n",
    "\n",
    "# 定義任務\n",
    "def collaborative_task(prompt):\n",
    "    # Agent1 生成初始文本\n",
    "    text1 = agent1.generate_text(prompt)\n",
    "    print(f\"{agent1.name} generated: {text1}\")\n",
    "\n",
    "    # Agent2 基於 Agent1 的文本進行擴展\n",
    "    text2 = agent2.generate_text(text1)\n",
    "    print(f\"{agent2.name} generated: {text2}\")\n",
    "\n",
    "    return text2\n",
    "\n",
    "# 執行任務\n",
    "prompt = \"Explain the why woman is hot.\"\n",
    "final_text = collaborative_task(prompt)\n",
    "print(f\"Final generated text: {final_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent1 generated: I want to know where cna find the girlfriend. I want her to be happy.\n",
      "\n",
      "I'm not sure if I'm going to get a girlfriend, but I know I can't. It's not like I have to. But I don't want a boyfriend. And I think I'll be able to find a girl.\n",
      "Agent2 generated: I want to know where cna find the girlfriend. I want her to be happy.\n",
      "\n",
      "I'm not sure if I'm going to get a girlfriend, but I know I can't. It's not like I have to. But I don't want a boyfriend. And I think I'll be able to find a girl.\n",
      "Final generated text: I want to know where cna find the girlfriend. I want her to be happy.\n",
      "\n",
      "I'm not sure if I'm going to get a girlfriend, but I know I can't. It's not like I have to. But I don't want a boyfriend. And I think I'll be able to find a girl.\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "# 加載預訓練模型和 tokenizer\n",
    "model_name = \"gpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 定義多代理系統\n",
    "class Agent:\n",
    "    def __init__(self, name, model, tokenizer):\n",
    "        self.name = name\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def generate_text(self, prompt, max_length=100, temperature=0.7, top_k=50, top_p=0.9):\n",
    "        input_ids = self.tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "        output = self.model.generate(\n",
    "            input_ids,\n",
    "            max_length=max_length,\n",
    "            num_return_sequences=1,\n",
    "            temperature=temperature,\n",
    "            top_k=top_k,\n",
    "            top_p=top_p,\n",
    "            no_repeat_ngram_size=2\n",
    "        )\n",
    "        generated_text = self.tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        return generated_text\n",
    "\n",
    "# 創建代理\n",
    "agent1 = Agent(\"Agent1\", model, tokenizer)\n",
    "agent2 = Agent(\"Agent2\", model, tokenizer)\n",
    "\n",
    "# 定義任務\n",
    "def collaborative_task(prompt):\n",
    "    # Agent1 生成初始文本\n",
    "    text1 = agent1.generate_text(prompt)\n",
    "    print(f\"{agent1.name} generated: {text1}\")\n",
    "\n",
    "    # Agent2 基於 Agent1 的文本進行擴展\n",
    "    text2 = agent2.generate_text(text1)\n",
    "    print(f\"{agent2.name} generated: {text2}\")\n",
    "\n",
    "    return text2\n",
    "\n",
    "# 執行任務\n",
    "prompt = \"I want to know where cna find the girlfriend.\"\n",
    "final_text = collaborative_task(prompt)\n",
    "print(f\"Final generated text: {final_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 檢查是否有可用的 GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (21.2.2)\n",
      "Collecting pip\n",
      "  Using cached pip-21.3.1-py3-none-any.whl (1.7 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 21.2.2\n",
      "    Uninstalling pip-21.2.2:\n",
      "      Successfully uninstalled pip-21.2.2\n",
      "Successfully installed pip-21.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts pip.exe, pip3.6.exe and pip3.exe are installed in 'c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (3.5.0)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from transformers) (0.0.53)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from transformers) (2023.6.3)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Using cached huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Using cached tokenizers-0.12.1.tar.gz (220 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "Note: you may need to restart the kernel to use updated packages.  Getting requirements to build wheel: finished with status 'done'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\python.exe' 'c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py' build_wheel 'C:\\Users\\johnn\\AppData\\Local\\Temp\\tmp3hrl2vgq'\n",
      "       cwd: C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-3frspxol\\tokenizers_0735d441251e448aae03c1ff8839671c\n",
      "  Complete output (51 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-3.6\n",
      "  creating build\\lib.win-amd64-3.6\\tokenizers\n",
      "  copying py_src\\tokenizers\\__init__.py -> build\\lib.win-amd64-3.6\\tokenizers\n",
      "  creating build\\lib.win-amd64-3.6\\tokenizers\\models\n",
      "  copying py_src\\tokenizers\\models\\__init__.py -> build\\lib.win-amd64-3.6\\tokenizers\\models\n",
      "  creating build\\lib.win-amd64-3.6\\tokenizers\\decoders\n",
      "  copying py_src\\tokenizers\\decoders\\__init__.py -> build\\lib.win-amd64-3.6\\tokenizers\\decoders\n",
      "  creating build\\lib.win-amd64-3.6\\tokenizers\\normalizers\n",
      "  copying py_src\\tokenizers\\normalizers\\__init__.py -> build\\lib.win-amd64-3.6\\tokenizers\\normalizers\n",
      "  creating build\\lib.win-amd64-3.6\\tokenizers\\pre_tokenizers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: requests in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from transformers) (2.24.0)\n",
      "Requirement already satisfied: dataclasses in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from transformers) (4.8.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from transformers) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from tqdm>=4.27->transformers) (5.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from importlib-metadata->transformers) (3.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: click in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from sacremoses->transformers) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from sacremoses->transformers) (1.1.1)\n",
      "Requirement already satisfied: six in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from sacremoses->transformers) (1.12.0)\n",
      "Building wheels for collected packages: tokenizers\n",
      "  Building wheel for tokenizers (pyproject.toml): started\n",
      "  Building wheel for tokenizers (pyproject.toml): finished with status 'error'\n",
      "Failed to build tokenizers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  copying py_src\\tokenizers\\pre_tokenizers\\__init__.py -> build\\lib.win-amd64-3.6\\tokenizers\\pre_tokenizers\n",
      "  creating build\\lib.win-amd64-3.6\\tokenizers\\processors\n",
      "  copying py_src\\tokenizers\\processors\\__init__.py -> build\\lib.win-amd64-3.6\\tokenizers\\processors\n",
      "  creating build\\lib.win-amd64-3.6\\tokenizers\\trainers\n",
      "  copying py_src\\tokenizers\\trainers\\__init__.py -> build\\lib.win-amd64-3.6\\tokenizers\\trainers\n",
      "  creating build\\lib.win-amd64-3.6\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\base_tokenizer.py -> build\\lib.win-amd64-3.6\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\bert_wordpiece.py -> build\\lib.win-amd64-3.6\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\byte_level_bpe.py -> build\\lib.win-amd64-3.6\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\char_level_bpe.py -> build\\lib.win-amd64-3.6\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\sentencepiece_bpe.py -> build\\lib.win-amd64-3.6\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\sentencepiece_unigram.py -> build\\lib.win-amd64-3.6\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\__init__.py -> build\\lib.win-amd64-3.6\\tokenizers\\implementations\n",
      "  creating build\\lib.win-amd64-3.6\\tokenizers\\tools\n",
      "  copying py_src\\tokenizers\\tools\\visualizer.py -> build\\lib.win-amd64-3.6\\tokenizers\\tools\n",
      "  copying py_src\\tokenizers\\tools\\__init__.py -> build\\lib.win-amd64-3.6\\tokenizers\\tools\n",
      "  copying py_src\\tokenizers\\__init__.pyi -> build\\lib.win-amd64-3.6\\tokenizers\n",
      "  copying py_src\\tokenizers\\models\\__init__.pyi -> build\\lib.win-amd64-3.6\\tokenizers\\models\n",
      "  copying py_src\\tokenizers\\decoders\\__init__.pyi -> build\\lib.win-amd64-3.6\\tokenizers\\decoders\n",
      "  copying py_src\\tokenizers\\normalizers\\__init__.pyi -> build\\lib.win-amd64-3.6\\tokenizers\\normalizers\n",
      "  copying py_src\\tokenizers\\pre_tokenizers\\__init__.pyi -> build\\lib.win-amd64-3.6\\tokenizers\\pre_tokenizers\n",
      "  copying py_src\\tokenizers\\processors\\__init__.pyi -> build\\lib.win-amd64-3.6\\tokenizers\\processors\n",
      "  copying py_src\\tokenizers\\trainers\\__init__.pyi -> build\\lib.win-amd64-3.6\\tokenizers\\trainers\n",
      "  copying py_src\\tokenizers\\tools\\visualizer-styles.css -> build\\lib.win-amd64-3.6\\tokenizers\\tools\n",
      "  running build_ext\n",
      "  running build_rust\n",
      "  error: can't find Rust compiler\n",
      "  \n",
      "  If you are using an outdated pip version, it is possible a prebuilt wheel is available for this package but pip is not able to install from it. Installing from the wheel would avoid the need for a Rust compiler.\n",
      "  \n",
      "  To update pip, run:\n",
      "  \n",
      "      pip install --upgrade pip\n",
      "  \n",
      "  and then retry package installation.\n",
      "  \n",
      "  If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for tokenizers\n",
      "ERROR: Could not build wheels for tokenizers, which is required to install pyproject.toml-based projects\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# 檢查是否有可用的 GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available, using CPU instead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n",
      "Requirement already satisfied: torch in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (0.15.2)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (0.13.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from torch) (3.10.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from torch) (3.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from torchvision) (2.32.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from torchvision) (9.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from torchvision) (2.1.3)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.5.1-cp310-cp310-win_amd64.whl (2.4 MB)\n",
      "     ---------------------------------------- 2.4/2.4 MB 1.5 MB/s eta 0:00:00\n",
      "  Downloading torchaudio-2.5.0-cp310-cp310-win_amd64.whl (2.4 MB)\n",
      "     ---------------------------------------- 2.4/2.4 MB 1.8 MB/s eta 0:00:00\n",
      "  Downloading torchaudio-2.4.1-cp310-cp310-win_amd64.whl (2.4 MB)\n",
      "     ---------------------------------------- 2.4/2.4 MB 1.9 MB/s eta 0:00:00\n",
      "  Downloading torchaudio-2.4.0-cp310-cp310-win_amd64.whl (2.4 MB)\n",
      "     ---------------------------------------- 2.4/2.4 MB 2.1 MB/s eta 0:00:00\n",
      "  Downloading torchaudio-2.3.1-cp310-cp310-win_amd64.whl (2.4 MB)\n",
      "     ---------------------------------------- 2.4/2.4 MB 2.3 MB/s eta 0:00:00\n",
      "  Downloading torchaudio-2.3.0-cp310-cp310-win_amd64.whl (2.4 MB)\n",
      "     ---------------------------------------- 2.4/2.4 MB 2.3 MB/s eta 0:00:00\n",
      "  Downloading torchaudio-2.2.2-cp310-cp310-win_amd64.whl (2.4 MB)\n",
      "     ---------------------------------------- 2.4/2.4 MB 2.2 MB/s eta 0:00:00\n",
      "  Downloading torchaudio-2.2.1-cp310-cp310-win_amd64.whl (2.4 MB)\n",
      "     ---------------------------------------- 2.4/2.4 MB 1.7 MB/s eta 0:00:00\n",
      "  Downloading torchaudio-2.2.0-cp310-cp310-win_amd64.whl (2.4 MB)\n",
      "     ---------------------------------------- 2.4/2.4 MB 2.1 MB/s eta 0:00:00\n",
      "  Downloading torchaudio-2.1.2-cp310-cp310-win_amd64.whl (2.3 MB)\n",
      "     ---------------------------------------- 2.3/2.3 MB 2.2 MB/s eta 0:00:00\n",
      "  Downloading torchaudio-2.1.1-cp310-cp310-win_amd64.whl (2.3 MB)\n",
      "     ---------------------------------------- 2.3/2.3 MB 1.4 MB/s eta 0:00:00\n",
      "  Downloading torchaudio-2.1.0-cp310-cp310-win_amd64.whl (2.3 MB)\n",
      "     ---------------------------------------- 2.3/2.3 MB 1.7 MB/s eta 0:00:00\n",
      "  Downloading torchaudio-2.0.2-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "     ---------------------------------------- 2.1/2.1 MB 2.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from requests->torchvision) (1.26.14)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Installing collected packages: torchaudio\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 0.13.1\n",
      "    Uninstalling torchaudio-0.13.1:\n",
      "      Successfully uninstalled torchaudio-0.13.1\n",
      "Successfully installed torchaudio-2.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (3.5.0)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from transformers) (0.0.53)\n",
      "Requirement already satisfied: dataclasses in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from transformers) (4.8.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from transformers) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from transformers) (21.3)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Using cached huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from transformers) (2.24.0)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Using cached tokenizers-0.12.1.tar.gz (220 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from tqdm>=4.27->transformers) (5.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from importlib-metadata->transformers) (3.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: six in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from sacremoses->transformers) (1.1.1)\n",
      "Requirement already satisfied: click in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (from sacremoses->transformers) (8.0.4)\n",
      "Building wheels for collected packages: tokenizers\n",
      "  Building wheel for tokenizers (pyproject.toml): started\n",
      "  Building wheel for tokenizers (pyproject.toml): finished with status 'error'\n",
      "Failed to build tokenizers\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\python.exe' 'c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py' build_wheel 'C:\\Users\\johnn\\AppData\\Local\\Temp\\tmps2d64ovs'\n",
      "       cwd: C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-2obuivqj\\tokenizers_5ccd901771db4b49904e7f8396080b05\n",
      "  Complete output (51 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-3.6\n",
      "  creating build\\lib.win-amd64-3.6\\tokenizers\n",
      "  copying py_src\\tokenizers\\__init__.py -> build\\lib.win-amd64-3.6\\tokenizers\n",
      "  creating build\\lib.win-amd64-3.6\\tokenizers\\models\n",
      "  copying py_src\\tokenizers\\models\\__init__.py -> build\\lib.win-amd64-3.6\\tokenizers\\models\n",
      "  creating build\\lib.win-amd64-3.6\\tokenizers\\decoders\n",
      "  copying py_src\\tokenizers\\decoders\\__init__.py -> build\\lib.win-amd64-3.6\\tokenizers\\decoders\n",
      "  creating build\\lib.win-amd64-3.6\\tokenizers\\normalizers\n",
      "  copying py_src\\tokenizers\\normalizers\\__init__.py -> build\\lib.win-amd64-3.6\\tokenizers\\normalizers\n",
      "  creating build\\lib.win-amd64-3.6\\tokenizers\\pre_tokenizers\n",
      "  copying py_src\\tokenizers\\pre_tokenizers\\__init__.py -> build\\lib.win-amd64-3.6\\tokenizers\\pre_tokenizers\n",
      "  creating build\\lib.win-amd64-3.6\\tokenizers\\processors\n",
      "  copying py_src\\tokenizers\\processors\\__init__.py -> build\\lib.win-amd64-3.6\\tokenizers\\processors\n",
      "  creating build\\lib.win-amd64-3.6\\tokenizers\\trainers\n",
      "  copying py_src\\tokenizers\\trainers\\__init__.py -> build\\lib.win-amd64-3.6\\tokenizers\\trainers\n",
      "  creating build\\lib.win-amd64-3.6\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\base_tokenizer.py -> build\\lib.win-amd64-3.6\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\bert_wordpiece.py -> build\\lib.win-amd64-3.6\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\byte_level_bpe.py -> build\\lib.win-amd64-3.6\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\char_level_bpe.py -> build\\lib.win-amd64-3.6\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\sentencepiece_bpe.py -> build\\lib.win-amd64-3.6\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\sentencepiece_unigram.py -> build\\lib.win-amd64-3.6\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\__init__.py -> build\\lib.win-amd64-3.6\\tokenizers\\implementations\n",
      "  creating build\\lib.win-amd64-3.6\\tokenizers\\tools\n",
      "  copying py_src\\tokenizers\\tools\\visualizer.py -> build\\lib.win-amd64-3.6\\tokenizers\\tools\n",
      "  copying py_src\\tokenizers\\tools\\__init__.py -> build\\lib.win-amd64-3.6\\tokenizers\\tools\n",
      "  copying py_src\\tokenizers\\__init__.pyi -> build\\lib.win-amd64-3.6\\tokenizers\n",
      "  copying py_src\\tokenizers\\models\\__init__.pyi -> build\\lib.win-amd64-3.6\\tokenizers\\models\n",
      "  copying py_src\\tokenizers\\decoders\\__init__.pyi -> build\\lib.win-amd64-3.6\\tokenizers\\decoders\n",
      "  copying py_src\\tokenizers\\normalizers\\__init__.pyi -> build\\lib.win-amd64-3.6\\tokenizers\\normalizers\n",
      "  copying py_src\\tokenizers\\pre_tokenizers\\__init__.pyi -> build\\lib.win-amd64-3.6\\tokenizers\\pre_tokenizers\n",
      "  copying py_src\\tokenizers\\processors\\__init__.pyi -> build\\lib.win-amd64-3.6\\tokenizers\\processors\n",
      "  copying py_src\\tokenizers\\trainers\\__init__.pyi -> build\\lib.win-amd64-3.6\\tokenizers\\trainers\n",
      "  copying py_src\\tokenizers\\tools\\visualizer-styles.css -> build\\lib.win-amd64-3.6\\tokenizers\\tools\n",
      "  running build_ext\n",
      "  running build_rust\n",
      "  error: can't find Rust compiler\n",
      "  \n",
      "  If you are using an outdated pip version, it is possible a prebuilt wheel is available for this package but pip is not able to install from it. Installing from the wheel would avoid the need for a Rust compiler.\n",
      "  \n",
      "  To update pip, run:\n",
      "  \n",
      "      pip install --upgrade pip\n",
      "  \n",
      "  and then retry package installation.\n",
      "  \n",
      "  If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for tokenizers\n",
      "ERROR: Could not build wheels for tokenizers, which is required to install pyproject.toml-based projects\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c408a28b1b744bd8ee917d41e1ebb01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ace3787a1aa453582e455eeadc3f839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c80335c347346ff8de4bb3582dd3a23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "918d91ff838240c9815c807c48fe6243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90cedd8307e740f7a99c4491f1219965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.02G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d7c2f13c094968b01bf51dc7501f28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff7febe9dc08415f8f1b01fd7486936f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "HTTPError",
     "evalue": "401 Client Error: Unauthorized for url: https://huggingface.co/facebook/rag-sequence-nq%5Cquestion_encoder_tokenizer/resolve/main/vocab.txt",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0671fd0e72fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mrag_model_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"facebook/rag-sequence-nq\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mrag_tokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRagTokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrag_model_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[0mrag_retriever\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRagRetriever\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrag_model_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"exact\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_dummy_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mrag_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRagSequenceForGeneration\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrag_model_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretriever\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrag_retriever\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages\\transformers\\tokenization_rag.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mquestion_encoder_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"question_encoder_tokenizer\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mgenerator_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"generator_tokenizer\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mquestion_encoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquestion_encoder_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquestion_encoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[0mgenerator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquestion_encoder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquestion_encoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages\\transformers\\tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    339\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer_class_fast\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer_class_py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m         raise ValueError(\n",
      "\u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1634\u001b[0m                         \u001b[0mresolved_vocab_files\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfile_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1635\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1636\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1638\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_file_name\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfull_file_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresolved_vocab_files\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1627\u001b[0m                         \u001b[0mproxies\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1628\u001b[0m                         \u001b[0mresume_download\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_download\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1629\u001b[1;33m                         \u001b[0mlocal_files_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1630\u001b[0m                     )\n\u001b[0;32m   1631\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages\\transformers\\file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[1;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, local_files_only)\u001b[0m\n\u001b[0;32m    953\u001b[0m             \u001b[0mresume_download\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_download\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m             \u001b[0muser_agent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muser_agent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 955\u001b[1;33m             \u001b[0mlocal_files_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    956\u001b[0m         )\n\u001b[0;32m    957\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages\\transformers\\file_utils.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[1;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, local_files_only)\u001b[0m\n\u001b[0;32m   1074\u001b[0m             \u001b[0mheaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"user-agent\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mhttp_user_agent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_agent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1075\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_redirects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1076\u001b[1;33m             \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1077\u001b[0m             \u001b[0metag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"X-Linked-Etag\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ETag\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1078\u001b[0m             \u001b[1;31m# We favor a custom header indicating the etag of the linked resource, and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    940\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 941\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    942\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    943\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/facebook/rag-sequence-nq%5Cquestion_encoder_tokenizer/resolve/main/vocab.txt"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, T5ForConditionalGeneration, T5Tokenizer, BartForConditionalGeneration, BartTokenizer, RagTokenizer, RagRetriever, RagSequenceForGeneration\n",
    "import torch\n",
    "\n",
    "# 檢查是否有可用的 GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 加載預訓練模型和 tokenizer\n",
    "gpt2_model_name = \"gpt2\"\n",
    "gpt2_model = GPT2LMHeadModel.from_pretrained(gpt2_model_name).to(device)\n",
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained(gpt2_model_name)\n",
    "\n",
    "t5_model_name = \"t5-small\"\n",
    "t5_model = T5ForConditionalGeneration.from_pretrained(t5_model_name).to(device)\n",
    "t5_tokenizer = T5Tokenizer.from_pretrained(t5_model_name)\n",
    "\n",
    "bart_model_name = \"facebook/bart-large\"\n",
    "bart_model = BartForConditionalGeneration.from_pretrained(bart_model_name).to(device)\n",
    "bart_tokenizer = BartTokenizer.from_pretrained(bart_model_name)\n",
    "\n",
    "rag_model_name = \"facebook/rag-sequence-nq\"\n",
    "rag_tokenizer = RagTokenizer.from_pretrained(rag_model_name)\n",
    "rag_retriever = RagRetriever.from_pretrained(rag_model_name, index_name=\"exact\", use_dummy_dataset=True)\n",
    "rag_model = RagSequenceForGeneration.from_pretrained(rag_model_name, retriever=rag_retriever).to(device)\n",
    "\n",
    "# 定義多代理系統\n",
    "class Agent:\n",
    "    def __init__(self, name, model, tokenizer, model_type=\"gpt2\"):\n",
    "        self.name = name\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model_type = model_type\n",
    "\n",
    "    def generate_text(self, prompt, max_length=100, temperature=0.7, top_k=50, top_p=0.9):\n",
    "        input_ids = self.tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "        output = self.model.generate(\n",
    "            input_ids,\n",
    "            max_length=max_length,\n",
    "            num_return_sequences=1,\n",
    "            temperature=temperature,\n",
    "            top_k=top_k,\n",
    "            top_p=top_p,\n",
    "            no_repeat_ngram_size=2\n",
    "        )\n",
    "        generated_text = self.tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        return generated_text\n",
    "\n",
    "# 創建代理\n",
    "agent1 = Agent(\"Agent1\", gpt2_model, gpt2_tokenizer, model_type=\"gpt2\")\n",
    "agent2 = Agent(\"Agent2\", t5_model, t5_tokenizer, model_type=\"t5\")\n",
    "agent3 = Agent(\"Agent3\", bart_model, bart_tokenizer, model_type=\"bart\")\n",
    "agent4 = Agent(\"Agent4\", gpt2_model, gpt2_tokenizer, model_type=\"gpt2\")  # 重複使用 GPT-2 作為示例\n",
    "agent5 = Agent(\"Agent5\", rag_model, rag_tokenizer, model_type=\"rag\")\n",
    "\n",
    "# 定義任務\n",
    "def collaborative_task(prompt):\n",
    "    # Agent1 生成初始文本\n",
    "    text1 = agent1.generate_text(prompt)\n",
    "    print(f\"{agent1.name} generated: {text1}\")\n",
    "\n",
    "    # Agent2 基於 Agent1 的文本進行擴展\n",
    "    text2 = agent2.generate_text(text1)\n",
    "    print(f\"{agent2.name} generated: {text2}\")\n",
    "\n",
    "    # Agent3 基於 Agent2 的文本進行擴展\n",
    "    text3 = agent3.generate_text(text2)\n",
    "    print(f\"{agent3.name} generated: {text3}\")\n",
    "\n",
    "    # Agent4 基於 Agent3 的文本進行擴展\n",
    "    text4 = agent4.generate_text(text3)\n",
    "    print(f\"{agent4.name} generated: {text4}\")\n",
    "\n",
    "    # Agent5 基於 Agent4 的文本進行擴展，並使用 RAG 進行檢索增強生成\n",
    "    text5 = agent5.generate_text(text4)\n",
    "    print(f\"{agent5.name} generated: {text5}\")\n",
    "\n",
    "    return text5\n",
    "\n",
    "# 執行任務\n",
    "prompt = \"Explain the concept of recursion in programming.\"\n",
    "final_text = collaborative_task(prompt)\n",
    "print(f\"Final generated text: {final_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: colorama in c:\\users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install colorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, T5ForConditionalGeneration, T5Tokenizer, BartForConditionalGeneration, BartTokenizer, RagTokenizer, RagRetriever, RagSequenceForGeneration\n",
    "import torch\n",
    "from colorama import Fore, Style\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mStarting collaborative task with prompt: \n",
      "You are a helpful assistant. Your task is to explain the concept of recursion in programming.\n",
      "Please provide a detailed explanation with examples. Make sure to cover the following points:\n",
      "1. What is recursion?\n",
      "2. How does recursion work?\n",
      "3. Provide a simple example of a recursive function.\n",
      "4. Explain the base case and recursive case.\n",
      "5. Discuss the advantages and disadvantages of using recursion.\n",
      "\u001b[0m\n",
      "================================================================================\n",
      "\u001b[32mAgent1 generated:\u001b[0m\n",
      "You are a helpful assistant. Your task is to explain the concept of recursion\n",
      "in programming. Please provide a detailed explanation with examples. Make sure\n",
      "to cover the following points: 1. What is recursion? 2. How does recursion work?\n",
      "3. Provide a simple example of a recursive function. 4. Explain the base case\n",
      "and recursive case. 5. Discuss the advantages and disadvantages of using\n",
      "recursion. 6. Describe the benefits of the recursive approach..\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32mAgent2 generated:\u001b[0m\n",
      "recursion. of a recurring function. 4. Explain the base case and reacursive\n",
      "case. 5. Discuss the advantages and disadvantages of using. 6. Describe the\n",
      "benefits of the'recursives approach'..\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mAgent3 generated:\u001b[0m\n",
      "recrecursion. 4. Explain the base case and reacursive case. 5. Discuss the\n",
      "advantages and disadvantages of using. 6. Describe the benefits of\n",
      "the'recursives approach'...\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32mAgent4 generated:\u001b[0m\n",
      "recrecursion. 4. Explain the base case and reacursive case. 5. Discuss the\n",
      "advantages and disadvantages of using. 6. Describe the benefits of\n",
      "the'recursives approach'... 7. Provide a brief overview of what's going on in\n",
      "the project. 8. Show how the team is working on the projects. 9. Present the\n",
      "results of their work. 10. Review the work and explain the rationale behind the\n",
      "decision. 11. Share the findings of your work with the community. 12.\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mFinal generated text:\u001b[0m\n",
      "recrecursion. 4. Explain the base case and reacursive case. 5. Discuss the\n",
      "advantages and disadvantages of using. 6. Describe the benefits of\n",
      "the'recursives approach'... 7. Provide a brief overview of what's going on in\n",
      "the project. 8. Show how the team is working on the projects. 9. Present the\n",
      "results of their work. 10. Review the work and explain the rationale behind the\n",
      "decision. 11. Share the findings of your work with the community. 12.\n"
     ]
    }
   ],
   "source": [
    "# 定義多代理系統\n",
    "class Agent:\n",
    "    def __init__(self, name, model, tokenizer, model_type=\"gpt2\"):\n",
    "        self.name = name\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model_type = model_type\n",
    "\n",
    "    def generate_text(self, prompt, max_length=100, temperature=0.7, top_k=50, top_p=0.9):\n",
    "        input_ids = self.tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "        output = self.model.generate(\n",
    "            input_ids,\n",
    "            max_length=max_length,\n",
    "            num_return_sequences=1,\n",
    "            temperature=temperature,\n",
    "            top_k=top_k,\n",
    "            top_p=top_p,\n",
    "            no_repeat_ngram_size=2\n",
    "        )\n",
    "        generated_text = self.tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        return generated_text\n",
    "\n",
    "    def format_text(self, text, line_length=80):\n",
    "        words = text.split()\n",
    "        lines = []\n",
    "        current_line = []\n",
    "        current_length = 0\n",
    "\n",
    "        for word in words:\n",
    "            if current_length + len(word) + 1 > line_length:\n",
    "                lines.append(' '.join(current_line))\n",
    "                current_line = [word]\n",
    "                current_length = len(word)\n",
    "            else:\n",
    "                current_line.append(word)\n",
    "                current_length += len(word) + 1\n",
    "\n",
    "        if current_line:\n",
    "            lines.append(' '.join(current_line))\n",
    "\n",
    "        return '\\n'.join(lines)\n",
    "\n",
    "    def ensure_complete_sentence(self, text, max_length):\n",
    "        sentences = text.split('. ')\n",
    "        complete_text = ''\n",
    "        for sentence in sentences:\n",
    "            if len(complete_text) + len(sentence) + 1 <= max_length:\n",
    "                complete_text += sentence + '. '\n",
    "            else:\n",
    "                break\n",
    "        return complete_text.strip()\n",
    "\n",
    "# 創建代理\n",
    "agent1 = Agent(\"Agent1\", gpt2_model, gpt2_tokenizer, model_type=\"gpt2\")\n",
    "agent2 = Agent(\"Agent2\", t5_model, t5_tokenizer, model_type=\"t5\")\n",
    "agent3 = Agent(\"Agent3\", bart_model, bart_tokenizer, model_type=\"bart\")\n",
    "agent4 = Agent(\"Agent4\", gpt2_model, gpt2_tokenizer, model_type=\"gpt2\")  # 重複使用 GPT-2 作為示例\n",
    "# agent5 = Agent(\"Agent5\", rag_model, rag_tokenizer, model_type=\"rag\")\n",
    "\n",
    "# 定義任務\n",
    "def collaborative_task(prompt, max_length=100):\n",
    "    print(f\"{Fore.BLUE}{Style.BRIGHT}Starting collaborative task with prompt: {prompt}{Style.RESET_ALL}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Agent1 生成初始文本\n",
    "    text1 = agent1.generate_text(prompt, max_length=max_length)\n",
    "    text1 = agent1.ensure_complete_sentence(text1, max_length)\n",
    "    formatted_text1 = agent1.format_text(text1)\n",
    "    print(f\"{Fore.GREEN}{agent1.name} generated:{Style.RESET_ALL}\\n{formatted_text1}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # Agent2 基於 Agent1 的文本進行擴展\n",
    "    text2 = agent2.generate_text(text1, max_length=max_length)\n",
    "    text2 = agent2.ensure_complete_sentence(text2, max_length)\n",
    "    formatted_text2 = agent2.format_text(text2)\n",
    "    print(f\"{Fore.GREEN}{agent2.name} generated:{Style.RESET_ALL}\\n{formatted_text2}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # Agent3 基於 Agent2 的文本進行擴展\n",
    "    text3 = agent3.generate_text(text2, max_length=max_length)\n",
    "    text3 = agent3.ensure_complete_sentence(text3, max_length)\n",
    "    formatted_text3 = agent3.format_text(text3)\n",
    "    print(f\"{Fore.GREEN}{agent3.name} generated:{Style.RESET_ALL}\\n{formatted_text3}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # Agent4 基於 Agent3 的文本進行擴展\n",
    "    text4 = agent4.generate_text(text3, max_length=max_length)\n",
    "    text4 = agent4.ensure_complete_sentence(text4, max_length)\n",
    "    formatted_text4 = agent4.format_text(text4)\n",
    "    print(f\"{Fore.GREEN}{agent4.name} generated:{Style.RESET_ALL}\\n{formatted_text4}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # # Agent5 基於 Agent4 的文本進行擴展，並使用 RAG 進行檢索增強生成\n",
    "    # text5 = agent5.generate_text(text4, max_length=max_length)\n",
    "    # text5 = agent5.ensure_complete_sentence(text5, max_length)\n",
    "    # formatted_text5 = agent5.format_text(text5)\n",
    "    # print(f\"{Fore.GREEN}{agent5.name} generated:{Style.RESET_ALL}\\n{formatted_text5}\")\n",
    "    # print(\"=\" * 80)\n",
    "\n",
    "    return formatted_text4\n",
    "\n",
    "# 執行任務\n",
    "prompt = \"\"\"\n",
    "You are a helpful assistant. Your task is to explain the concept of recursion in programming.\n",
    "Please provide a detailed explanation with examples. Make sure to cover the following points:\n",
    "1. What is recursion?\n",
    "2. How does recursion work?\n",
    "3. Provide a simple example of a recursive function.\n",
    "4. Explain the base case and recursive case.\n",
    "5. Discuss the advantages and disadvantages of using recursion.\n",
    "\"\"\"\n",
    "final_text = collaborative_task(prompt, max_length=500)\n",
    "print(f\"{Fore.BLUE}{Style.BRIGHT}Final generated text:{Style.RESET_ALL}\\n{final_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyMuPDF\n",
      "  Downloading PyMuPDF-1.24.13-cp39-abi3-win_amd64.whl (16.2 MB)\n",
      "     ---------------------------------------- 16.2/16.2 MB 1.8 MB/s eta 0:00:00\n",
      "Installing collected packages: PyMuPDF\n",
      "Successfully installed PyMuPDF-1.24.13\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages)\n",
      "  WARNING: The script pymupdf.exe is installed in 'c:\\Users\\johnn\\anaconda3\\envs\\ptoch_2023\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.5-py3-none-any.whl (2.4 MB)\n",
      "     ---------------------------------------- 2.4/2.4 MB 1.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from langchain-community) (9.0.0)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.6 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from langchain-community) (0.3.7)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from langchain-community) (6.0)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from langchain-community) (2.32.3)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from langchain-community) (0.3.15)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from langchain-community) (3.10.10)\n",
      "Collecting SQLAlchemy<2.0.36,>=1.4\n",
      "  Downloading SQLAlchemy-2.0.35-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "     ---------------------------------------- 2.1/2.1 MB 2.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from langchain-community) (0.1.142)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0\n",
      "  Downloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (22.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.17.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0\n",
      "  Downloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
      "     ---------------------------------------- 49.5/49.5 kB 2.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from langchain<0.4.0,>=0.3.6->langchain-community) (2.9.2)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from langchain<0.4.0,>=0.3.6->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.11)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.2)\n",
      "Collecting python-dotenv>=0.21.0\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from requests<3,>=2->langchain-community) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from requests<3,>=2->langchain-community) (2022.12.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from SQLAlchemy<2.0.36,>=1.4->langchain-community) (3.1.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (3.5.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.6->langchain-community) (2.23.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.6->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.0)\n",
      "Installing collected packages: SQLAlchemy, python-dotenv, marshmallow, httpx-sse, dataclasses-json, pydantic-settings, langchain-community\n",
      "  Attempting uninstall: SQLAlchemy\n",
      "    Found existing installation: SQLAlchemy 2.0.36\n",
      "    Uninstalling SQLAlchemy-2.0.36:\n",
      "      Successfully uninstalled SQLAlchemy-2.0.36\n",
      "Successfully installed SQLAlchemy-2.0.35 dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.5 marshmallow-3.23.1 pydantic-settings-2.6.1 python-dotenv-1.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages)\n",
      "  WARNING: The script dotenv.exe is installed in 'c:\\Users\\johnn\\anaconda3\\envs\\ptoch_2023\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.3.0-py3-none-any.whl (268 kB)\n",
      "     ------------------------------------ 268.7/268.7 kB 870.4 kB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from sentence-transformers) (4.67.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from sentence-transformers) (9.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from sentence-transformers) (0.26.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from sentence-transformers) (2.0.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from sentence-transformers) (1.10.0)\n",
      "Collecting transformers<5.0.0,>=4.41.0\n",
      "  Using cached transformers-4.46.2-py3-none-any.whl (10.0 MB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2023.5.0)\n",
      "Requirement already satisfied: requests in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Collecting safetensors>=0.4.1\n",
      "  Downloading safetensors-0.4.5-cp310-none-win_amd64.whl (285 kB)\n",
      "     ------------------------------------ 285.9/285.9 kB 883.5 kB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Collecting tokenizers<0.21,>=0.20\n",
      "  Downloading tokenizers-0.20.3-cp310-none-win_amd64.whl (2.4 MB)\n",
      "     ---------------------------------------- 2.4/2.4 MB 1.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2023.6.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (1.26.14)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Installing collected packages: safetensors, tokenizers, transformers, sentence-transformers\n",
      "  Attempting uninstall: safetensors\n",
      "    Found existing installation: safetensors 0.3.1\n",
      "    Uninstalling safetensors-0.3.1:\n",
      "      Successfully uninstalled safetensors-0.3.1\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.13.3\n",
      "    Uninstalling tokenizers-0.13.3:\n",
      "      Successfully uninstalled tokenizers-0.13.3\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.30.0\n",
      "    Uninstalling transformers-4.30.0:\n",
      "      Successfully uninstalled transformers-4.30.0\n",
      "Successfully installed safetensors-0.4.5 sentence-transformers-3.3.0 tokenizers-0.20.3 transformers-4.46.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages)\n",
      "  WARNING: The script transformers-cli.exe is installed in 'c:\\Users\\johnn\\anaconda3\\envs\\ptoch_2023\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement chromadb (from versions: none)\n",
      "ERROR: No matching distribution found for chromadb\n"
     ]
    }
   ],
   "source": [
    "pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-cpp-python\n",
      "  Downloading llama_cpp_python-0.1.10.tar.gz (518 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Building wheels for collected packages: llama-cpp-python\n",
      "  Building wheel for llama-cpp-python (pyproject.toml): started\n",
      "  Building wheel for llama-cpp-python (pyproject.toml): finished with status 'error'\n",
      "Failed to build llama-cpp-python\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\python.exe' 'c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py' build_wheel 'C:\\Users\\johnn\\AppData\\Local\\Temp\\tmpel_5a_a5'\n",
      "       cwd: C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-chbq0lwf\\llama-cpp-python_f151d421210e44b68ef9e6317482000b\n",
      "  Complete output (193 lines):\n",
      "  \n",
      "  \n",
      "  --------------------------------------------------------------------------------\n",
      "  -- Trying 'Ninja (Visual Studio 17 2022 x64 v143)' generator\n",
      "  --------------------------------\n",
      "  ---------------------------\n",
      "  ----------------------\n",
      "  -----------------\n",
      "  ------------\n",
      "  -------\n",
      "  --\n",
      "  Not searching for unused variables given on the command line.\n",
      "  CMake Deprecation Warning at CMakeLists.txt:1 (cmake_minimum_required):\n",
      "    Compatibility with CMake < 3.5 will be removed from a future version of\n",
      "    CMake.\n",
      "  \n",
      "    Update the VERSION argument <min> value or use a ...<max> suffix to tell\n",
      "    CMake that the project does not need compatibility with older versions.\n",
      "  \n",
      "  \n",
      "  -- The C compiler identification is unknown\n",
      "  CMake Error at CMakeLists.txt:3 (ENABLE_LANGUAGE):\n",
      "    No CMAKE_C_COMPILER could be found.\n",
      "  \n",
      "    Tell CMake where to find the compiler by setting either the environment\n",
      "    variable \"CC\" or the CMake cache entry CMAKE_C_COMPILER to the full path to\n",
      "    the compiler, or to the compiler name if it is in the PATH.\n",
      "  \n",
      "  \n",
      "  -- Configuring incomplete, errors occurred!\n",
      "  --\n",
      "  -------\n",
      "  ------------\n",
      "  -----------------\n",
      "  ----------------------\n",
      "  ---------------------------\n",
      "  --------------------------------\n",
      "  -- Trying 'Ninja (Visual Studio 17 2022 x64 v143)' generator - failure\n",
      "  --------------------------------------------------------------------------------\n",
      "  \n",
      "  \n",
      "  \n",
      "  --------------------------------------------------------------------------------\n",
      "  -- Trying 'Visual Studio 17 2022 x64 v143' generator\n",
      "  --------------------------------\n",
      "  ---------------------------\n",
      "  ----------------------\n",
      "  -----------------\n",
      "  ------------\n",
      "  -------\n",
      "  --\n",
      "  Not searching for unused variables given on the command line.\n",
      "  CMake Deprecation Warning at CMakeLists.txt:1 (cmake_minimum_required):\n",
      "    Compatibility with CMake < 3.5 will be removed from a future version of\n",
      "    CMake.\n",
      "  \n",
      "    Update the VERSION argument <min> value or use a ...<max> suffix to tell\n",
      "    CMake that the project does not need compatibility with older versions.\n",
      "  \n",
      "  \n",
      "  -- Selecting Windows SDK version 10.0.22000.0 to target Windows 10.0.26100.\n",
      "  -- The C compiler identification is MSVC 19.41.34123.0\n",
      "  -- Detecting C compiler ABI info\n",
      "  -- Detecting C compiler ABI info - done\n",
      "  -- Check for working C compiler: C:/Program Files/Microsoft Visual Studio/2022/Community/VC/Tools/MSVC/14.41.34120/bin/Hostx64/x64/cl.exe - skipped\n",
      "  -- Detecting C compile features\n",
      "  -- Detecting C compile features - done\n",
      "  -- The CXX compiler identification is MSVC 19.41.34123.0\n",
      "  -- Detecting CXX compiler ABI info\n",
      "  -- Detecting CXX compiler ABI info - done\n",
      "  -- Check for working CXX compiler: C:/Program Files/Microsoft Visual Studio/2022/Community/VC/Tools/MSVC/14.41.34120/bin/Hostx64/x64/cl.exe - skipped\n",
      "  -- Detecting CXX compile features\n",
      "  -- Detecting CXX compile features - done\n",
      "  -- Configuring done (9.7s)\n",
      "  -- Generating done (0.0s)\n",
      "  -- Build files have been written to: C:/Users/johnn/AppData/Local/Temp/pip-install-chbq0lwf/llama-cpp-python_f151d421210e44b68ef9e6317482000b/_cmake_test_compile/build\n",
      "  --\n",
      "  -------\n",
      "  ------------\n",
      "  -----------------\n",
      "  ----------------------\n",
      "  ---------------------------\n",
      "  --------------------------------\n",
      "  -- Trying 'Visual Studio 17 2022 x64 v143' generator - success\n",
      "  --------------------------------------------------------------------------------\n",
      "  \n",
      "  Configuring Project\n",
      "    Working directory:\n",
      "      C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-chbq0lwf\\llama-cpp-python_f151d421210e44b68ef9e6317482000b\\_skbuild\\win-amd64-3.6\\cmake-build\n",
      "    Command:\n",
      "      'C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-build-env-j7poc0mx\\overlay\\Lib\\site-packages\\cmake\\data\\bin/cmake.exe' 'C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-chbq0lwf\\llama-cpp-python_f151d421210e44b68ef9e6317482000b' -G 'Visual Studio 17 2022' '-DCMAKE_INSTALL_PREFIX:PATH=C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-chbq0lwf\\llama-cpp-python_f151d421210e44b68ef9e6317482000b\\_skbuild\\win-amd64-3.6\\cmake-install' -DPYTHON_VERSION_STRING:STRING=3.6.13 -DSKBUILD:INTERNAL=TRUE '-DCMAKE_MODULE_PATH:PATH=C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-build-env-j7poc0mx\\overlay\\Lib\\site-packages\\skbuild\\resources\\cmake' '-DPYTHON_EXECUTABLE:PATH=c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\python.exe' '-DPYTHON_INCLUDE_DIR:PATH=c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\Include' '-DPYTHON_LIBRARY:PATH=c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\libs\\python36.lib' '-DPython_EXECUTABLE:PATH=c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\python.exe' '-DPython_ROOT_DIR:PATH=c:\\Users\\johnn\\anaconda3\\envs\\fomc_new' '-DPython_INCLUDE_DIR:PATH=c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\Include' -DPython_FIND_REGISTRY:STRING=NEVER '-DPython3_EXECUTABLE:PATH=c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\python.exe' '-DPython3_ROOT_DIR:PATH=c:\\Users\\johnn\\anaconda3\\envs\\fomc_new' '-DPython3_INCLUDE_DIR:PATH=c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\Include' -DPython3_FIND_REGISTRY:STRING=NEVER -T v143 -A x64 -DCMAKE_BUILD_TYPE:STRING=Release\n",
      "  \n",
      "  -- Selecting Windows SDK version 10.0.22000.0 to target Windows 10.0.26100.\n",
      "  -- The C compiler identification is MSVC 19.41.34123.0\n",
      "  -- The CXX compiler identification is MSVC 19.41.34123.0\n",
      "  -- Detecting C compiler ABI info\n",
      "  -- Detecting C compiler ABI info - failed\n",
      "  -- Check for working C compiler: C:/Program Files/Microsoft Visual Studio/2022/Community/VC/Tools/MSVC/14.41.34120/bin/Hostx64/x64/cl.exe\n",
      "  -- Check for working C compiler: C:/Program Files/Microsoft Visual Studio/2022/Community/VC/Tools/MSVC/14.41.34120/bin/Hostx64/x64/cl.exe - broken\n",
      "  CMake Error at C:/Users/johnn/AppData/Local/Temp/pip-build-env-j7poc0mx/overlay/Lib/site-packages/cmake/data/share/cmake-3.28/Modules/CMakeTestCCompiler.cmake:67 (message):\n",
      "    The C compiler\n",
      "  \n",
      "      \"C:/Program Files/Microsoft Visual Studio/2022/Community/VC/Tools/MSVC/14.41.34120/bin/Hostx64/x64/cl.exe\"\n",
      "  \n",
      "    is not able to compile a simple test program.\n",
      "  \n",
      "    It fails with the following output:\n",
      "  \n",
      "      Change Dir: 'C:/Users/johnn/AppData/Local/Temp/pip-install-chbq0lwf/llama-cpp-python_f151d421210e44b68ef9e6317482000b/_skbuild/win-amd64-3.6/cmake-build/CMakeFiles/CMakeScratch/TryCompile-k0ytut'\n",
      "  \n",
      "      Run Build Command(s): \"C:/Program Files/Microsoft Visual Studio/2022/Community/MSBuild/Current/Bin/amd64/MSBuild.exe\" cmTC_d1d78.vcxproj /p:Configuration=Debug /p:Platform=x64 /p:VisualStudioVersion=17.0 /v:n\n",
      "      .NET Framework ??MSBuild ?\\xef\\x8e\\x87謓\\xb1 17.11.9+a69bbaaf5\n",
      "      \\xe6\\x92\\x8c\\xe8\\x84\\xa9??\\xef\\x95\\x9d?\\xe6\\x92梁\\xae\\x87\\xe8\\x94\\xad??2025/3/23 \\xe9\\x8a\\x9d\\xef\\x95\\x9d? 01:59:38??\n",
      "  \n",
      "      \\xe8\\x9d倦\\x80\\xe6\\x9a\\xba?1 (?\\xee\\x93\\x91頨\\xab?\\xe6\\xa0\\xbc?) \\xe9\\x8a\\x9d\\xef\\x93\\x82?\\xe6\\x92\\xa0\\xef\\x8e\\x87? \"C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-chbq0lwf\\llama-cpp-python_f151d421210e44b68ef9e6317482000b\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-k0ytut\\cmTC_d1d78.vcxproj\"??\n",
      "      PrepareForBuild:\n",
      "        \\xe7\\x94\\x87?謓剜\\x92梁\\xae\\x87??獢\\x85? \"cmTC_d1d78.dir\\Debug\\\"??\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppBuild.targets(541,5): warning MSB8029: The Intermediate directory or Output directory cannot reside under the Temporary directory as it could lead to issues with incremental build. [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-chbq0lwf\\llama-cpp-python_f151d421210e44b68ef9e6317482000b\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-k0ytut\\cmTC_d1d78.vcxproj]\n",
      "        Structured output is enabled. The formatting of compiler diagnostics will reflect the error hierarchy. See https://aka.ms/cpp/structured-output for more details.\n",
      "        \\xe7\\x94\\x87?謓剜\\x92梁\\xae\\x87??獢\\x85? \"C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-chbq0lwf\\llama-cpp-python_f151d421210e44b68ef9e6317482000b\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-k0ytut\\Debug\\\"??\n",
      "        \\xe7\\x94\\x87?謓剜\\x92梁\\xae\\x87??獢\\x85? \"cmTC_d1d78.dir\\Debug\\cmTC_d1d78.tlog\\\"??\n",
      "      InitializeBuildStatus:\n",
      "        ?\\xe6\\x9c\\x9b謘\\x93?\\xef\\x8b\\xa9?\\xe9\\x88\\xad?\"AlwaysCreate\"\\xe5\\x9a\\x97\\xef\\x97\\xba?\\xe7\\x94\\x87\\xe6\\x96\\x97餈\\xa4?\\xe5\\x85賊\\x81\\xa3\\xe8\\x9d\\xa1?\"cmTC_d1d78.dir\\Debug\\cmTC_d1d78.tlog\\unsuccessfulbuild\"??\n",
      "        \\xe7\\x94\\x87?謓剝\\x9c\\x88\\xef\\x93\\x81謆\\x9c?蹇\\x9c??\\xe5\\x94\\xbe? \"cmTC_d1d78.dir\\Debug\\cmTC_d1d78.tlog\\unsuccessfulbuild\"??\n",
      "      ClCompile:\n",
      "        C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.41.34120\\bin\\HostX64\\x64\\CL.exe /c /Zi /W1 /WX- /diagnostics:column /Od /Ob0 /D _MBCS /D WIN32 /D _WINDOWS /D \"CMAKE_INTDIR=\\\"Debug\\\"\" /Gm- /RTC1 /MDd /GS /fp:precise /Zc:wchar_t /Zc:forScope /Zc:inline /Fo\"cmTC_d1d78.dir\\Debug\\\\\" /Fd\"cmTC_d1d78.dir\\Debug\\vc143.pdb\" /external:W1 /Gd /TC /errorReport:queue \"C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-chbq0lwf\\llama-cpp-python_f151d421210e44b68ef9e6317482000b\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-k0ytut\\testCCompiler.c\"\n",
      "        Microsoft (R) C/C++ Optimizing Compiler Version 19.41.34123 for x64\n",
      "        Copyright (C) Microsoft Corporation.  All rights reserved.\n",
      "        cl /c /Zi /W1 /WX- /diagnostics:column /Od /Ob0 /D _MBCS /D WIN32 /D _WINDOWS /D \"CMAKE_INTDIR=\\\"Debug\\\"\" /Gm- /RTC1 /MDd /GS /fp:precise /Zc:wchar_t /Zc:forScope /Zc:inline /Fo\"cmTC_d1d78.dir\\Debug\\\\\" /Fd\"cmTC_d1d78.dir\\Debug\\vc143.pdb\" /external:W1 /Gd /TC /errorReport:queue \"C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-chbq0lwf\\llama-cpp-python_f151d421210e44b68ef9e6317482000b\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-k0ytut\\testCCompiler.c\"\n",
      "        testCCompiler.c\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003: ?\\xe2\\x8a\\xa5??\\xe7\\x91\\x81??\\xef\\x8b\\xa9??\\xef\\x84\\x92璆菟\\x9b遴高\\xee\\x8f\\xbb?\\xe7\\x91\\x81?\\xe7\\x91\\xbc?\"CL.exe\"?蹐肘stem.IO.DirectoryNotFoundException: ?\\xe6\\x9b\\x86??\\xe5\\x95\\x97璆\\x9d\\xe6\\x95\\xba?'C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-chbq0lwf\\llama-cpp-python_f151d421210e44b68ef9e6317482000b\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-k0ytut\\cmTC_d1d78.dir\\Debug\\cmTC_d1d78.tlog' ?\\xef\\x84\\x91??\\xe5\\x85\\xb8???[C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-chbq0lwf\\llama-cpp-python_f151d421210e44b68ef9e6317482000b\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-k0ytut\\cmTC_d1d78.vcxproj]\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003:    ??System.IO.__Error.WinIOError(Int32 errorCode, String maybeFullPath) [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-chbq0lwf\\llama-cpp-python_f151d421210e44b68ef9e6317482000b\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-k0ytut\\cmTC_d1d78.vcxproj]\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003:    ??System.IO.FileSystemEnumerableIterator`1.CommonInit() [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-chbq0lwf\\llama-cpp-python_f151d421210e44b68ef9e6317482000b\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-k0ytut\\cmTC_d1d78.vcxproj]\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003:    ??System.IO.FileSystemEnumerableIterator`1..ctor(String path, String originalUserPath, String searchPattern, SearchOption searchOption, SearchResultHandler`1 resultHandler, Boolean checkHost) [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-chbq0lwf\\llama-cpp-python_f151d421210e44b68ef9e6317482000b\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-k0ytut\\cmTC_d1d78.vcxproj]\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003:    ??System.IO.Directory.GetFiles(String path, String searchPattern) [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-chbq0lwf\\llama-cpp-python_f151d421210e44b68ef9e6317482000b\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-k0ytut\\cmTC_d1d78.vcxproj]\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003:    ??Microsoft.Build.Utilities.TrackedDependencies.ExpandWildcards(ITaskItem[] expand) [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-chbq0lwf\\llama-cpp-python_f151d421210e44b68ef9e6317482000b\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-k0ytut\\cmTC_d1d78.vcxproj]\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003:    ??Microsoft.Build.CPPTasks.TrackedVCToolTask.DeleteFiles(ITaskItem[] filesToDelete) [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-chbq0lwf\\llama-cpp-python_f151d421210e44b68ef9e6317482000b\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-k0ytut\\cmTC_d1d78.vcxproj]\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003:    ??Microsoft.Build.CPPTasks.CL.PostExecuteTool(Int32 exitCode) [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-chbq0lwf\\llama-cpp-python_f151d421210e44b68ef9e6317482000b\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-k0ytut\\cmTC_d1d78.vcxproj]\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003:    ??Microsoft.Build.CPPTasks.TrackedVCToolTask.ExecuteTool(String pathToTool, String responseFileCommands, String commandLineCommands) [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-chbq0lwf\\llama-cpp-python_f151d421210e44b68ef9e6317482000b\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-k0ytut\\cmTC_d1d78.vcxproj]\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003:    ??Microsoft.Build.CPPTasks.CL.ExecuteTool(String pathToTool, String responseFileCommands, String commandLineCommands) [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-chbq0lwf\\llama-cpp-python_f151d421210e44b68ef9e6317482000b\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-k0ytut\\cmTC_d1d78.vcxproj]\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003:    ??Microsoft.Build.Utilities.ToolTask.Execute() [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-chbq0lwf\\llama-cpp-python_f151d421210e44b68ef9e6317482000b\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-k0ytut\\cmTC_d1d78.vcxproj]\n",
      "      \\xe6\\x92\\xa0\\xef\\x8e\\x87? \"C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-chbq0lwf\\llama-cpp-python_f151d421210e44b68ef9e6317482000b\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-k0ytut\\cmTC_d1d78.vcxproj\" (?\\xee\\x93\\x91頨\\xab?\\xe6\\xa0\\xbc?) \\xe6\\x92梁\\xae\\x87\\xe8\\x94剜\\x91堆\\x97\\xbb? -- \\xe6\\x86剜\\x9c\\x9b???\n",
      "  \n",
      "      \\xe6\\x92梁\\xae\\x87\\xe8\\x94剜\\x86剜\\x9c\\x9b???\n",
      "  \n",
      "      \"C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-chbq0lwf\\llama-cpp-python_f151d421210e44b68ef9e6317482000b\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-k0ytut\\cmTC_d1d78.vcxproj\" (?\\xee\\x93\\x91頨\\xab?\\xe6\\xa0\\xbc?) (1) ->\n",
      "      (PrepareForBuild ?\\xe6\\xa0\\xbc?) ->\n",
      "        C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppBuild.targets(541,5): warning MSB8029: The Intermediate directory or Output directory cannot reside under the Temporary directory as it could lead to issues with incremental build. [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-chbq0lwf\\llama-cpp-python_f151d421210e44b68ef9e6317482000b\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-k0ytut\\cmTC_d1d78.vcxproj]\n",
      "  \n",
      "  \n",
      "      \"C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-chbq0lwf\\llama-cpp-python_f151d421210e44b68ef9e6317482000b\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-k0ytut\\cmTC_d1d78.vcxproj\" (?\\xee\\x93\\x91頨\\xab?\\xe6\\xa0\\xbc?) (1) ->\n",
      "      (ClCompile ?\\xe6\\xa0\\xbc?) ->\n",
      "        C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003: ?\\xe2\\x8a\\xa5??\\xe7\\x91\\x81??\\xef\\x8b\\xa9??\\xef\\x84\\x92璆菟\\x9b遴高\\xee\\x8f\\xbb?\\xe7\\x91\\x81?\\xe7\\x91\\xbc?\"CL.exe\"?蹐肘stem.IO.DirectoryNotFoundException: ?\\xe6\\x9b\\x86??\\xe5\\x95\\x97璆\\x9d\\xe6\\x95\\xba?'C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-chbq0lwf\\llama-cpp-python_f151d421210e44b68ef9e6317482000b\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-k0ytut\\cmTC_d1d78.dir\\Debug\\cmTC_d1d78.tlog' ?\\xef\\x84\\x91??\\xe5\\x85\\xb8???[C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-chbq0lwf\\llama-cpp-python_f151d421210e44b68ef9e6317482000b\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-k0ytut\\cmTC_d1d78.vcxproj]\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003:    ??System.IO.__Error.WinIOError(Int32 errorCode, String maybeFullPath) [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-chbq0lwf\\llama-cpp-python_f151d421210e44b68ef9e6317482000b\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-k0ytut\\cmTC_d1d78.vcxproj]\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003:    ??System.IO.FileSystemEnumerableIterator`1.CommonInit() [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-chbq0lwf\\llama-cpp-python_f151d421210e44b68ef9e6317482000b\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-k0ytut\\cmTC_d1d78.vcxproj]\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003:    ??System.IO.FileSystemEnumerableIterator`1..ctor(String path, String originalUserPath, String searchPattern, SearchOption searchOption, SearchResultHandler`1 resultHandler, Boolean checkHost) [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-chbq0lwf\\llama-cpp-python_f151d421210e44b68ef9e6317482000b\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-k0ytut\\cmTC_d1d78.vcxproj]\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003:    ??System.IO.Directory.GetFiles(String path, String searchPattern) [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-chbq0lwf\\llama-cpp-python_f151d421210e44b68ef9e6317482000b\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-k0ytut\\cmTC_d1d78.vcxproj]\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003:    ??Microsoft.Build.Utilities.TrackedDependencies.ExpandWildcards(ITaskItem[] expand) [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-chbq0lwf\\llama-cpp-python_f151d421210e44b68ef9e6317482000b\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-k0ytut\\cmTC_d1d78.vcxproj]\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003:    ??Microsoft.Build.CPPTasks.TrackedVCToolTask.DeleteFiles(ITaskItem[] filesToDelete) [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-chbq0lwf\\llama-cpp-python_f151d421210e44b68ef9e6317482000b\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-k0ytut\\cmTC_d1d78.vcxproj]\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003:    ??Microsoft.Build.CPPTasks.CL.PostExecuteTool(Int32 exitCode) [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-chbq0lwf\\llama-cpp-python_f151d421210e44b68ef9e6317482000b\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-k0ytut\\cmTC_d1d78.vcxproj]\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003:    ??Microsoft.Build.CPPTasks.TrackedVCToolTask.ExecuteTool(String pathToTool, String responseFileCommands, String commandLineCommands) [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-chbq0lwf\\llama-cpp-python_f151d421210e44b68ef9e6317482000b\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-k0ytut\\cmTC_d1d78.vcxproj]\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003:    ??Microsoft.Build.CPPTasks.CL.ExecuteTool(String pathToTool, String responseFileCommands, String commandLineCommands) [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-chbq0lwf\\llama-cpp-python_f151d421210e44b68ef9e6317482000b\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-k0ytut\\cmTC_d1d78.vcxproj]\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003:    ??Microsoft.Build.Utilities.ToolTask.Execute() [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-chbq0lwf\\llama-cpp-python_f151d421210e44b68ef9e6317482000b\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-k0ytut\\cmTC_d1d78.vcxproj]\n",
      "  \n",
      "          1 ?\\xef\\x95\\xa0\\xe9\\x83\\x8e??\n",
      "          1 ?\\xef\\x95∴\\x97\\x84\\xe9\\x9a\\xa4?\n",
      "  \n",
      "      \\xe8\\x9d秋\\x9a\\xa9??蹇\\x9c? 00:00:00.47\n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "    CMake will not be able to correctly generate this project.\n",
      "  Call Stack (most recent call first):\n",
      "    CMakeLists.txt:3 (project)\n",
      "  \n",
      "  \n",
      "  -- Configuring incomplete, errors occurred!\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-build-env-j7poc0mx\\overlay\\Lib\\site-packages\\skbuild\\setuptools_wrap.py\", line 639, in setup\n",
      "      languages=cmake_languages,\n",
      "    File \"C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-build-env-j7poc0mx\\overlay\\Lib\\site-packages\\skbuild\\cmaker.py\", line 333, in configure\n",
      "      \"An error occurred while configuring with CMake.\\n\"\n",
      "  \n",
      "  An error occurred while configuring with CMake.\n",
      "    Command:\n",
      "      'C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-build-env-j7poc0mx\\overlay\\Lib\\site-packages\\cmake\\data\\bin/cmake.exe' 'C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-chbq0lwf\\llama-cpp-python_f151d421210e44b68ef9e6317482000b' -G 'Visual Studio 17 2022' '-DCMAKE_INSTALL_PREFIX:PATH=C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-chbq0lwf\\llama-cpp-python_f151d421210e44b68ef9e6317482000b\\_skbuild\\win-amd64-3.6\\cmake-install' -DPYTHON_VERSION_STRING:STRING=3.6.13 -DSKBUILD:INTERNAL=TRUE '-DCMAKE_MODULE_PATH:PATH=C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-build-env-j7poc0mx\\overlay\\Lib\\site-packages\\skbuild\\resources\\cmake' '-DPYTHON_EXECUTABLE:PATH=c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\python.exe' '-DPYTHON_INCLUDE_DIR:PATH=c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\Include' '-DPYTHON_LIBRARY:PATH=c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\libs\\python36.lib' '-DPython_EXECUTABLE:PATH=c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\python.exe' '-DPython_ROOT_DIR:PATH=c:\\Users\\johnn\\anaconda3\\envs\\fomc_new' '-DPython_INCLUDE_DIR:PATH=c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\Include' -DPython_FIND_REGISTRY:STRING=NEVER '-DPython3_EXECUTABLE:PATH=c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\python.exe' '-DPython3_ROOT_DIR:PATH=c:\\Users\\johnn\\anaconda3\\envs\\fomc_new' '-DPython3_INCLUDE_DIR:PATH=c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\Include' -DPython3_FIND_REGISTRY:STRING=NEVER -T v143 -A x64 -DCMAKE_BUILD_TYPE:STRING=Release\n",
      "    Source directory:\n",
      "      C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-chbq0lwf\\llama-cpp-python_f151d421210e44b68ef9e6317482000b\n",
      "    Working directory:\n",
      "      C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-chbq0lwf\\llama-cpp-python_f151d421210e44b68ef9e6317482000b\\_skbuild\\win-amd64-3.6\\cmake-build\n",
      "  Please see CMake's output for more information.\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for llama-cpp-python\n",
      "ERROR: Could not build wheels for llama-cpp-python, which is required to install pyproject.toml-based projects\n"
     ]
    }
   ],
   "source": [
    "pip install llama-cpp-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-cpp-python\n",
      "  Using cached llama_cpp_python-0.1.10.tar.gz (518 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Building wheels for collected packages: llama-cpp-python\n",
      "  Building wheel for llama-cpp-python (pyproject.toml): started\n",
      "  Building wheel for llama-cpp-python (pyproject.toml): finished with status 'error'\n",
      "Failed to build llama-cpp-python\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\python.exe' 'c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py' build_wheel 'C:\\Users\\johnn\\AppData\\Local\\Temp\\tmpega2r8k5'\n",
      "       cwd: C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-we5ot1af\\llama-cpp-python_d51e72c0718d44199f9c97194bbee132\n",
      "  Complete output (193 lines):\n",
      "  \n",
      "  \n",
      "  --------------------------------------------------------------------------------\n",
      "  -- Trying 'Ninja (Visual Studio 17 2022 x64 v143)' generator\n",
      "  --------------------------------\n",
      "  ---------------------------\n",
      "  ----------------------\n",
      "  -----------------\n",
      "  ------------\n",
      "  -------\n",
      "  --\n",
      "  Not searching for unused variables given on the command line.\n",
      "  CMake Deprecation Warning at CMakeLists.txt:1 (cmake_minimum_required):\n",
      "    Compatibility with CMake < 3.5 will be removed from a future version of\n",
      "    CMake.\n",
      "  \n",
      "    Update the VERSION argument <min> value or use a ...<max> suffix to tell\n",
      "    CMake that the project does not need compatibility with older versions.\n",
      "  \n",
      "  \n",
      "  -- The C compiler identification is unknown\n",
      "  CMake Error at CMakeLists.txt:3 (ENABLE_LANGUAGE):\n",
      "    No CMAKE_C_COMPILER could be found.\n",
      "  \n",
      "    Tell CMake where to find the compiler by setting either the environment\n",
      "    variable \"CC\" or the CMake cache entry CMAKE_C_COMPILER to the full path to\n",
      "    the compiler, or to the compiler name if it is in the PATH.\n",
      "  \n",
      "  \n",
      "  -- Configuring incomplete, errors occurred!\n",
      "  --\n",
      "  -------\n",
      "  ------------\n",
      "  -----------------\n",
      "  ----------------------\n",
      "  ---------------------------\n",
      "  --------------------------------\n",
      "  -- Trying 'Ninja (Visual Studio 17 2022 x64 v143)' generator - failure\n",
      "  --------------------------------------------------------------------------------\n",
      "  \n",
      "  \n",
      "  \n",
      "  --------------------------------------------------------------------------------\n",
      "  -- Trying 'Visual Studio 17 2022 x64 v143' generator\n",
      "  --------------------------------\n",
      "  ---------------------------\n",
      "  ----------------------\n",
      "  -----------------\n",
      "  ------------\n",
      "  -------\n",
      "  --\n",
      "  Not searching for unused variables given on the command line.\n",
      "  CMake Deprecation Warning at CMakeLists.txt:1 (cmake_minimum_required):\n",
      "    Compatibility with CMake < 3.5 will be removed from a future version of\n",
      "    CMake.\n",
      "  \n",
      "    Update the VERSION argument <min> value or use a ...<max> suffix to tell\n",
      "    CMake that the project does not need compatibility with older versions.\n",
      "  \n",
      "  \n",
      "  -- Selecting Windows SDK version 10.0.22000.0 to target Windows 10.0.26100.\n",
      "  -- The C compiler identification is MSVC 19.41.34123.0\n",
      "  -- Detecting C compiler ABI info\n",
      "  -- Detecting C compiler ABI info - done\n",
      "  -- Check for working C compiler: C:/Program Files/Microsoft Visual Studio/2022/Community/VC/Tools/MSVC/14.41.34120/bin/Hostx64/x64/cl.exe - skipped\n",
      "  -- Detecting C compile features\n",
      "  -- Detecting C compile features - done\n",
      "  -- The CXX compiler identification is MSVC 19.41.34123.0\n",
      "  -- Detecting CXX compiler ABI info\n",
      "  -- Detecting CXX compiler ABI info - done\n",
      "  -- Check for working CXX compiler: C:/Program Files/Microsoft Visual Studio/2022/Community/VC/Tools/MSVC/14.41.34120/bin/Hostx64/x64/cl.exe - skipped\n",
      "  -- Detecting CXX compile features\n",
      "  -- Detecting CXX compile features - done\n",
      "  -- Configuring done (4.8s)\n",
      "  -- Generating done (0.0s)\n",
      "  -- Build files have been written to: C:/Users/johnn/AppData/Local/Temp/pip-install-we5ot1af/llama-cpp-python_d51e72c0718d44199f9c97194bbee132/_cmake_test_compile/build\n",
      "  --\n",
      "  -------\n",
      "  ------------\n",
      "  -----------------\n",
      "  ----------------------\n",
      "  ---------------------------\n",
      "  --------------------------------\n",
      "  -- Trying 'Visual Studio 17 2022 x64 v143' generator - success\n",
      "  --------------------------------------------------------------------------------\n",
      "  \n",
      "  Configuring Project\n",
      "    Working directory:\n",
      "      C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-we5ot1af\\llama-cpp-python_d51e72c0718d44199f9c97194bbee132\\_skbuild\\win-amd64-3.6\\cmake-build\n",
      "    Command:\n",
      "      'C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-build-env-tv9x52x2\\overlay\\Lib\\site-packages\\cmake\\data\\bin/cmake.exe' 'C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-we5ot1af\\llama-cpp-python_d51e72c0718d44199f9c97194bbee132' -G 'Visual Studio 17 2022' '-DCMAKE_INSTALL_PREFIX:PATH=C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-we5ot1af\\llama-cpp-python_d51e72c0718d44199f9c97194bbee132\\_skbuild\\win-amd64-3.6\\cmake-install' -DPYTHON_VERSION_STRING:STRING=3.6.13 -DSKBUILD:INTERNAL=TRUE '-DCMAKE_MODULE_PATH:PATH=C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-build-env-tv9x52x2\\overlay\\Lib\\site-packages\\skbuild\\resources\\cmake' '-DPYTHON_EXECUTABLE:PATH=c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\python.exe' '-DPYTHON_INCLUDE_DIR:PATH=c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\Include' '-DPYTHON_LIBRARY:PATH=c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\libs\\python36.lib' '-DPython_EXECUTABLE:PATH=c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\python.exe' '-DPython_ROOT_DIR:PATH=c:\\Users\\johnn\\anaconda3\\envs\\fomc_new' '-DPython_INCLUDE_DIR:PATH=c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\Include' -DPython_FIND_REGISTRY:STRING=NEVER '-DPython3_EXECUTABLE:PATH=c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\python.exe' '-DPython3_ROOT_DIR:PATH=c:\\Users\\johnn\\anaconda3\\envs\\fomc_new' '-DPython3_INCLUDE_DIR:PATH=c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\Include' -DPython3_FIND_REGISTRY:STRING=NEVER -T v143 -A x64 -DCMAKE_BUILD_TYPE:STRING=Release\n",
      "  \n",
      "  -- Selecting Windows SDK version 10.0.22000.0 to target Windows 10.0.26100.\n",
      "  -- The C compiler identification is MSVC 19.41.34123.0\n",
      "  -- The CXX compiler identification is MSVC 19.41.34123.0\n",
      "  -- Detecting C compiler ABI info\n",
      "  -- Detecting C compiler ABI info - failed\n",
      "  -- Check for working C compiler: C:/Program Files/Microsoft Visual Studio/2022/Community/VC/Tools/MSVC/14.41.34120/bin/Hostx64/x64/cl.exe\n",
      "  -- Check for working C compiler: C:/Program Files/Microsoft Visual Studio/2022/Community/VC/Tools/MSVC/14.41.34120/bin/Hostx64/x64/cl.exe - broken\n",
      "  CMake Error at C:/Users/johnn/AppData/Local/Temp/pip-build-env-tv9x52x2/overlay/Lib/site-packages/cmake/data/share/cmake-3.28/Modules/CMakeTestCCompiler.cmake:67 (message):\n",
      "    The C compiler\n",
      "  \n",
      "      \"C:/Program Files/Microsoft Visual Studio/2022/Community/VC/Tools/MSVC/14.41.34120/bin/Hostx64/x64/cl.exe\"\n",
      "  \n",
      "    is not able to compile a simple test program.\n",
      "  \n",
      "    It fails with the following output:\n",
      "  \n",
      "      Change Dir: 'C:/Users/johnn/AppData/Local/Temp/pip-install-we5ot1af/llama-cpp-python_d51e72c0718d44199f9c97194bbee132/_skbuild/win-amd64-3.6/cmake-build/CMakeFiles/CMakeScratch/TryCompile-x2ry7p'\n",
      "  \n",
      "      Run Build Command(s): \"C:/Program Files/Microsoft Visual Studio/2022/Community/MSBuild/Current/Bin/amd64/MSBuild.exe\" cmTC_87eb9.vcxproj /p:Configuration=Debug /p:Platform=x64 /p:VisualStudioVersion=17.0 /v:n\n",
      "      .NET Framework ??MSBuild ?\\xef\\x8e\\x87謓\\xb1 17.11.9+a69bbaaf5\n",
      "      \\xe6\\x92\\x8c\\xe8\\x84\\xa9??\\xef\\x95\\x9d?\\xe6\\x92梁\\xae\\x87\\xe8\\x94\\xad??2025/3/23 \\xe9\\x8a\\x9d\\xef\\x95\\x9d? 02:02:03??\n",
      "  \n",
      "      \\xe8\\x9d倦\\x80\\xe6\\x9a\\xba?1 (?\\xee\\x93\\x91頨\\xab?\\xe6\\xa0\\xbc?) \\xe9\\x8a\\x9d\\xef\\x93\\x82?\\xe6\\x92\\xa0\\xef\\x8e\\x87? \"C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-we5ot1af\\llama-cpp-python_d51e72c0718d44199f9c97194bbee132\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-x2ry7p\\cmTC_87eb9.vcxproj\"??\n",
      "      PrepareForBuild:\n",
      "        \\xe7\\x94\\x87?謓剜\\x92梁\\xae\\x87??獢\\x85? \"cmTC_87eb9.dir\\Debug\\\"??\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppBuild.targets(541,5): warning MSB8029: The Intermediate directory or Output directory cannot reside under the Temporary directory as it could lead to issues with incremental build. [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-we5ot1af\\llama-cpp-python_d51e72c0718d44199f9c97194bbee132\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-x2ry7p\\cmTC_87eb9.vcxproj]\n",
      "        Structured output is enabled. The formatting of compiler diagnostics will reflect the error hierarchy. See https://aka.ms/cpp/structured-output for more details.\n",
      "        \\xe7\\x94\\x87?謓剜\\x92梁\\xae\\x87??獢\\x85? \"C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-we5ot1af\\llama-cpp-python_d51e72c0718d44199f9c97194bbee132\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-x2ry7p\\Debug\\\"??\n",
      "        \\xe7\\x94\\x87?謓剜\\x92梁\\xae\\x87??獢\\x85? \"cmTC_87eb9.dir\\Debug\\cmTC_87eb9.tlog\\\"??\n",
      "      InitializeBuildStatus:\n",
      "        ?\\xe6\\x9c\\x9b謘\\x93?\\xef\\x8b\\xa9?\\xe9\\x88\\xad?\"AlwaysCreate\"\\xe5\\x9a\\x97\\xef\\x97\\xba?\\xe7\\x94\\x87\\xe6\\x96\\x97餈\\xa4?\\xe5\\x85賊\\x81\\xa3\\xe8\\x9d\\xa1?\"cmTC_87eb9.dir\\Debug\\cmTC_87eb9.tlog\\unsuccessfulbuild\"??\n",
      "        \\xe7\\x94\\x87?謓剝\\x9c\\x88\\xef\\x93\\x81謆\\x9c?蹇\\x9c??\\xe5\\x94\\xbe? \"cmTC_87eb9.dir\\Debug\\cmTC_87eb9.tlog\\unsuccessfulbuild\"??\n",
      "      ClCompile:\n",
      "        C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.41.34120\\bin\\HostX64\\x64\\CL.exe /c /Zi /W1 /WX- /diagnostics:column /Od /Ob0 /D _MBCS /D WIN32 /D _WINDOWS /D \"CMAKE_INTDIR=\\\"Debug\\\"\" /Gm- /RTC1 /MDd /GS /fp:precise /Zc:wchar_t /Zc:forScope /Zc:inline /Fo\"cmTC_87eb9.dir\\Debug\\\\\" /Fd\"cmTC_87eb9.dir\\Debug\\vc143.pdb\" /external:W1 /Gd /TC /errorReport:queue \"C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-we5ot1af\\llama-cpp-python_d51e72c0718d44199f9c97194bbee132\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-x2ry7p\\testCCompiler.c\"\n",
      "        Microsoft (R) C/C++ Optimizing Compiler Version 19.41.34123 for x64\n",
      "        Copyright (C) Microsoft Corporation.  All rights reserved.\n",
      "        cl /c /Zi /W1 /WX- /diagnostics:column /Od /Ob0 /D _MBCS /D WIN32 /D _WINDOWS /D \"CMAKE_INTDIR=\\\"Debug\\\"\" /Gm- /RTC1 /MDd /GS /fp:precise /Zc:wchar_t /Zc:forScope /Zc:inline /Fo\"cmTC_87eb9.dir\\Debug\\\\\" /Fd\"cmTC_87eb9.dir\\Debug\\vc143.pdb\" /external:W1 /Gd /TC /errorReport:queue \"C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-we5ot1af\\llama-cpp-python_d51e72c0718d44199f9c97194bbee132\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-x2ry7p\\testCCompiler.c\"\n",
      "        testCCompiler.c\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003: ?\\xe2\\x8a\\xa5??\\xe7\\x91\\x81??\\xef\\x8b\\xa9??\\xef\\x84\\x92璆菟\\x9b遴高\\xee\\x8f\\xbb?\\xe7\\x91\\x81?\\xe7\\x91\\xbc?\"CL.exe\"?蹐肘stem.IO.DirectoryNotFoundException: ?\\xe6\\x9b\\x86??\\xe5\\x95\\x97璆\\x9d\\xe6\\x95\\xba?'C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-we5ot1af\\llama-cpp-python_d51e72c0718d44199f9c97194bbee132\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-x2ry7p\\cmTC_87eb9.dir\\Debug\\cmTC_87eb9.tlog' ?\\xef\\x84\\x91??\\xe5\\x85\\xb8???[C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-we5ot1af\\llama-cpp-python_d51e72c0718d44199f9c97194bbee132\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-x2ry7p\\cmTC_87eb9.vcxproj]\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003:    ??System.IO.__Error.WinIOError(Int32 errorCode, String maybeFullPath) [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-we5ot1af\\llama-cpp-python_d51e72c0718d44199f9c97194bbee132\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-x2ry7p\\cmTC_87eb9.vcxproj]\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003:    ??System.IO.FileSystemEnumerableIterator`1.CommonInit() [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-we5ot1af\\llama-cpp-python_d51e72c0718d44199f9c97194bbee132\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-x2ry7p\\cmTC_87eb9.vcxproj]\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003:    ??System.IO.FileSystemEnumerableIterator`1..ctor(String path, String originalUserPath, String searchPattern, SearchOption searchOption, SearchResultHandler`1 resultHandler, Boolean checkHost) [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-we5ot1af\\llama-cpp-python_d51e72c0718d44199f9c97194bbee132\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-x2ry7p\\cmTC_87eb9.vcxproj]\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003:    ??System.IO.Directory.GetFiles(String path, String searchPattern) [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-we5ot1af\\llama-cpp-python_d51e72c0718d44199f9c97194bbee132\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-x2ry7p\\cmTC_87eb9.vcxproj]\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003:    ??Microsoft.Build.Utilities.TrackedDependencies.ExpandWildcards(ITaskItem[] expand) [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-we5ot1af\\llama-cpp-python_d51e72c0718d44199f9c97194bbee132\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-x2ry7p\\cmTC_87eb9.vcxproj]\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003:    ??Microsoft.Build.CPPTasks.TrackedVCToolTask.DeleteFiles(ITaskItem[] filesToDelete) [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-we5ot1af\\llama-cpp-python_d51e72c0718d44199f9c97194bbee132\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-x2ry7p\\cmTC_87eb9.vcxproj]\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003:    ??Microsoft.Build.CPPTasks.CL.PostExecuteTool(Int32 exitCode) [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-we5ot1af\\llama-cpp-python_d51e72c0718d44199f9c97194bbee132\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-x2ry7p\\cmTC_87eb9.vcxproj]\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003:    ??Microsoft.Build.CPPTasks.TrackedVCToolTask.ExecuteTool(String pathToTool, String responseFileCommands, String commandLineCommands) [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-we5ot1af\\llama-cpp-python_d51e72c0718d44199f9c97194bbee132\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-x2ry7p\\cmTC_87eb9.vcxproj]\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003:    ??Microsoft.Build.CPPTasks.CL.ExecuteTool(String pathToTool, String responseFileCommands, String commandLineCommands) [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-we5ot1af\\llama-cpp-python_d51e72c0718d44199f9c97194bbee132\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-x2ry7p\\cmTC_87eb9.vcxproj]\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003:    ??Microsoft.Build.Utilities.ToolTask.Execute() [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-we5ot1af\\llama-cpp-python_d51e72c0718d44199f9c97194bbee132\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-x2ry7p\\cmTC_87eb9.vcxproj]\n",
      "      \\xe6\\x92\\xa0\\xef\\x8e\\x87? \"C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-we5ot1af\\llama-cpp-python_d51e72c0718d44199f9c97194bbee132\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-x2ry7p\\cmTC_87eb9.vcxproj\" (?\\xee\\x93\\x91頨\\xab?\\xe6\\xa0\\xbc?) \\xe6\\x92梁\\xae\\x87\\xe8\\x94剜\\x91堆\\x97\\xbb? -- \\xe6\\x86剜\\x9c\\x9b???\n",
      "  \n",
      "      \\xe6\\x92梁\\xae\\x87\\xe8\\x94剜\\x86剜\\x9c\\x9b???\n",
      "  \n",
      "      \"C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-we5ot1af\\llama-cpp-python_d51e72c0718d44199f9c97194bbee132\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-x2ry7p\\cmTC_87eb9.vcxproj\" (?\\xee\\x93\\x91頨\\xab?\\xe6\\xa0\\xbc?) (1) ->\n",
      "      (PrepareForBuild ?\\xe6\\xa0\\xbc?) ->\n",
      "        C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppBuild.targets(541,5): warning MSB8029: The Intermediate directory or Output directory cannot reside under the Temporary directory as it could lead to issues with incremental build. [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-we5ot1af\\llama-cpp-python_d51e72c0718d44199f9c97194bbee132\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-x2ry7p\\cmTC_87eb9.vcxproj]\n",
      "  \n",
      "  \n",
      "      \"C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-we5ot1af\\llama-cpp-python_d51e72c0718d44199f9c97194bbee132\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-x2ry7p\\cmTC_87eb9.vcxproj\" (?\\xee\\x93\\x91頨\\xab?\\xe6\\xa0\\xbc?) (1) ->\n",
      "      (ClCompile ?\\xe6\\xa0\\xbc?) ->\n",
      "        C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003: ?\\xe2\\x8a\\xa5??\\xe7\\x91\\x81??\\xef\\x8b\\xa9??\\xef\\x84\\x92璆菟\\x9b遴高\\xee\\x8f\\xbb?\\xe7\\x91\\x81?\\xe7\\x91\\xbc?\"CL.exe\"?蹐肘stem.IO.DirectoryNotFoundException: ?\\xe6\\x9b\\x86??\\xe5\\x95\\x97璆\\x9d\\xe6\\x95\\xba?'C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-we5ot1af\\llama-cpp-python_d51e72c0718d44199f9c97194bbee132\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-x2ry7p\\cmTC_87eb9.dir\\Debug\\cmTC_87eb9.tlog' ?\\xef\\x84\\x91??\\xe5\\x85\\xb8???[C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-we5ot1af\\llama-cpp-python_d51e72c0718d44199f9c97194bbee132\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-x2ry7p\\cmTC_87eb9.vcxproj]\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003:    ??System.IO.__Error.WinIOError(Int32 errorCode, String maybeFullPath) [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-we5ot1af\\llama-cpp-python_d51e72c0718d44199f9c97194bbee132\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-x2ry7p\\cmTC_87eb9.vcxproj]\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003:    ??System.IO.FileSystemEnumerableIterator`1.CommonInit() [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-we5ot1af\\llama-cpp-python_d51e72c0718d44199f9c97194bbee132\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-x2ry7p\\cmTC_87eb9.vcxproj]\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003:    ??System.IO.FileSystemEnumerableIterator`1..ctor(String path, String originalUserPath, String searchPattern, SearchOption searchOption, SearchResultHandler`1 resultHandler, Boolean checkHost) [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-we5ot1af\\llama-cpp-python_d51e72c0718d44199f9c97194bbee132\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-x2ry7p\\cmTC_87eb9.vcxproj]\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003:    ??System.IO.Directory.GetFiles(String path, String searchPattern) [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-we5ot1af\\llama-cpp-python_d51e72c0718d44199f9c97194bbee132\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-x2ry7p\\cmTC_87eb9.vcxproj]\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003:    ??Microsoft.Build.Utilities.TrackedDependencies.ExpandWildcards(ITaskItem[] expand) [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-we5ot1af\\llama-cpp-python_d51e72c0718d44199f9c97194bbee132\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-x2ry7p\\cmTC_87eb9.vcxproj]\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003:    ??Microsoft.Build.CPPTasks.TrackedVCToolTask.DeleteFiles(ITaskItem[] filesToDelete) [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-we5ot1af\\llama-cpp-python_d51e72c0718d44199f9c97194bbee132\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-x2ry7p\\cmTC_87eb9.vcxproj]\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003:    ??Microsoft.Build.CPPTasks.CL.PostExecuteTool(Int32 exitCode) [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-we5ot1af\\llama-cpp-python_d51e72c0718d44199f9c97194bbee132\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-x2ry7p\\cmTC_87eb9.vcxproj]\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003:    ??Microsoft.Build.CPPTasks.TrackedVCToolTask.ExecuteTool(String pathToTool, String responseFileCommands, String commandLineCommands) [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-we5ot1af\\llama-cpp-python_d51e72c0718d44199f9c97194bbee132\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-x2ry7p\\cmTC_87eb9.vcxproj]\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003:    ??Microsoft.Build.CPPTasks.CL.ExecuteTool(String pathToTool, String responseFileCommands, String commandLineCommands) [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-we5ot1af\\llama-cpp-python_d51e72c0718d44199f9c97194bbee132\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-x2ry7p\\cmTC_87eb9.vcxproj]\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Microsoft\\VC\\v170\\Microsoft.CppCommon.targets(755,5): error MSB6003:    ??Microsoft.Build.Utilities.ToolTask.Execute() [C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-we5ot1af\\llama-cpp-python_d51e72c0718d44199f9c97194bbee132\\_skbuild\\win-amd64-3.6\\cmake-build\\CMakeFiles\\CMakeScratch\\TryCompile-x2ry7p\\cmTC_87eb9.vcxproj]\n",
      "  \n",
      "          1 ?\\xef\\x95\\xa0\\xe9\\x83\\x8e??\n",
      "          1 ?\\xef\\x95∴\\x97\\x84\\xe9\\x9a\\xa4?\n",
      "  \n",
      "      \\xe8\\x9d秋\\x9a\\xa9??蹇\\x9c? 00:00:00.38\n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "    CMake will not be able to correctly generate this project.\n",
      "  Call Stack (most recent call first):\n",
      "    CMakeLists.txt:3 (project)\n",
      "  \n",
      "  \n",
      "  -- Configuring incomplete, errors occurred!\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-build-env-tv9x52x2\\overlay\\Lib\\site-packages\\skbuild\\setuptools_wrap.py\", line 639, in setup\n",
      "      languages=cmake_languages,\n",
      "    File \"C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-build-env-tv9x52x2\\overlay\\Lib\\site-packages\\skbuild\\cmaker.py\", line 333, in configure\n",
      "      \"An error occurred while configuring with CMake.\\n\"\n",
      "  \n",
      "  An error occurred while configuring with CMake.\n",
      "    Command:\n",
      "      'C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-build-env-tv9x52x2\\overlay\\Lib\\site-packages\\cmake\\data\\bin/cmake.exe' 'C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-we5ot1af\\llama-cpp-python_d51e72c0718d44199f9c97194bbee132' -G 'Visual Studio 17 2022' '-DCMAKE_INSTALL_PREFIX:PATH=C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-we5ot1af\\llama-cpp-python_d51e72c0718d44199f9c97194bbee132\\_skbuild\\win-amd64-3.6\\cmake-install' -DPYTHON_VERSION_STRING:STRING=3.6.13 -DSKBUILD:INTERNAL=TRUE '-DCMAKE_MODULE_PATH:PATH=C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-build-env-tv9x52x2\\overlay\\Lib\\site-packages\\skbuild\\resources\\cmake' '-DPYTHON_EXECUTABLE:PATH=c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\python.exe' '-DPYTHON_INCLUDE_DIR:PATH=c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\Include' '-DPYTHON_LIBRARY:PATH=c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\libs\\python36.lib' '-DPython_EXECUTABLE:PATH=c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\python.exe' '-DPython_ROOT_DIR:PATH=c:\\Users\\johnn\\anaconda3\\envs\\fomc_new' '-DPython_INCLUDE_DIR:PATH=c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\Include' -DPython_FIND_REGISTRY:STRING=NEVER '-DPython3_EXECUTABLE:PATH=c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\python.exe' '-DPython3_ROOT_DIR:PATH=c:\\Users\\johnn\\anaconda3\\envs\\fomc_new' '-DPython3_INCLUDE_DIR:PATH=c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\Include' -DPython3_FIND_REGISTRY:STRING=NEVER -T v143 -A x64 -DCMAKE_BUILD_TYPE:STRING=Release\n",
      "    Source directory:\n",
      "      C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-we5ot1af\\llama-cpp-python_d51e72c0718d44199f9c97194bbee132\n",
      "    Working directory:\n",
      "      C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-install-we5ot1af\\llama-cpp-python_d51e72c0718d44199f9c97194bbee132\\_skbuild\\win-amd64-3.6\\cmake-build\n",
      "  Please see CMake's output for more information.\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for llama-cpp-python\n",
      "ERROR: Could not build wheels for llama-cpp-python, which is required to install pyproject.toml-based projects\n"
     ]
    }
   ],
   "source": [
    "pip install llama-cpp-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "future feature annotations is not defined (agent.py, line 2)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m3343\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[0;32m\"<ipython-input-2-4041228eb4ec>\"\u001b[0m, line \u001b[0;32m1\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    import langchain\n",
      "  File \u001b[0;32m\"c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages\\langchain\\__init__.py\"\u001b[0m, line \u001b[0;32m8\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    from langchain.agents import MRKLChain, ReActChain, SelfAskWithSearchChain\n",
      "\u001b[1;36m  File \u001b[1;32m\"c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages\\langchain\\agents\\__init__.py\"\u001b[1;36m, line \u001b[1;32m2\u001b[1;36m, in \u001b[1;35m<module>\u001b[1;36m\u001b[0m\n\u001b[1;33m    from langchain.agents.agent import Agent\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages\\langchain\\agents\\agent.py\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    from __future__ import annotations\u001b[0m\n\u001b[1;37m                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m future feature annotations is not defined\n"
     ]
    }
   ],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/username/ollama.git\n",
      "  Cloning https://github.com/username/ollama.git to c:\\users\\johnn\\appdata\\local\\temp\\pip-req-build-jptcecd6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none -q https://github.com/username/ollama.git 'C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-req-build-jptcecd6'\n",
      "  remote: Repository not found.\n",
      "  fatal: repository 'https://github.com/username/ollama.git/' not found\n",
      "WARNING: Discarding git+https://github.com/username/ollama.git. Command errored out with exit status 128: git clone --filter=blob:none -q https://github.com/username/ollama.git 'C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-req-build-jptcecd6' Check the logs for full command output.\n",
      "ERROR: Command errored out with exit status 128: git clone --filter=blob:none -q https://github.com/username/ollama.git 'C:\\Users\\johnn\\AppData\\Local\\Temp\\pip-req-build-jptcecd6' Check the logs for full command output.\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/username/ollama.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "future feature annotations is not defined (agent.py, line 2)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m3343\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[0;32m\"<ipython-input-10-4041228eb4ec>\"\u001b[0m, line \u001b[0;32m1\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    import langchain\n",
      "  File \u001b[0;32m\"c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages\\langchain\\__init__.py\"\u001b[0m, line \u001b[0;32m8\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    from langchain.agents import MRKLChain, ReActChain, SelfAskWithSearchChain\n",
      "\u001b[1;36m  File \u001b[1;32m\"c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages\\langchain\\agents\\__init__.py\"\u001b[1;36m, line \u001b[1;32m2\u001b[1;36m, in \u001b[1;35m<module>\u001b[1;36m\u001b[0m\n\u001b[1;33m    from langchain.agents.agent import Agent\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"c:\\Users\\johnn\\anaconda3\\envs\\fomc_new\\lib\\site-packages\\langchain\\agents\\agent.py\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    from __future__ import annotations\u001b[0m\n\u001b[1;37m                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m future feature annotations is not defined\n"
     ]
    }
   ],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "\n",
    "# Ensure the correct path to the PDF file\n",
    "loader = PyMuPDFLoader(\"Virtual_characters.pdf\")\n",
    "PDF_data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'Virtual_characters.pdf', 'file_path': 'Virtual_characters.pdf', 'page': 0, 'total_pages': 1, 'format': 'PDF 1.7', 'title': '', 'author': '琪婕 黃', 'subject': '', 'keywords': '', 'creator': '適用於 Microsoft 365 的 Microsoft® Word', 'producer': '適用於 Microsoft 365 的 Microsoft® Word', 'creationDate': \"D:20240121015900+08'00'\", 'modDate': \"D:20240121015900+08'00'\", 'trapped': ''}, page_content=\"Alison Hawk, a 28-year-old female researcher, stands out not only for her genius \\nin the scientific community but also for her remarkable capacities in data \\nanalysis and cryptography. With an intelligence score of 90, a physical strength \\nof 70, and a charm of 75, Alison's talents extend beyond the conventional \\nboundaries. Her ability to conduct complex experiments under extreme \\nconditions has caused a significant stir in the academic world, propelling her to \\nthe forefront of her field. Her groundbreaking work has not only pushed the limits \\nof academia but also attracted attention from governmental and private sectors. \\n \\nHowever, Alison's true motives and goals remain shrouded in mystery. This \\nenigmatic nature, coupled with her exceptional skill set, makes her adept at \\ntackling complex problems and handling emergencies with ease. Despite the \\nhigh acclaim for her work, Alison remains reticent about her personal life, which \\nis almost an enigma to the outside world. The curiosity and speculation \\nsurrounding her true intentions only add to her mystique, making Alison Hawk a \\nfigure of intrigue and admiration in her professional and personal circles. \\n\")]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PDF_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=5)\n",
    "all_splits = text_splitter.split_documents(PDF_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnn\\AppData\\Local\\Temp\\ipykernel_1372\\1245334059.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding = HuggingFaceEmbeddings(model_name=model_name,\n",
      "c:\\Users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages\\torchvision\\datapoints\\__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "c:\\Users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages\\torchvision\\transforms\\v2\\__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "embedding = HuggingFaceEmbeddings(model_name=model_name,\n",
    "                                  model_kwargs=model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed and store the texts\n",
    "# Supplying a persist_directory will store the embeddings on disk\n",
    "from langchain.vectorstores import Chroma\n",
    "persist_directory = 'db'\n",
    "vectordb = Chroma.from_documents(documents=all_splits, embedding=embedding, persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences between September and November FOMC statements have been saved to 'fomc_diff_result.txt'\n"
     ]
    }
   ],
   "source": [
    "import difflib\n",
    "import requests\n",
    "\n",
    "# Function to fetch the content of the FOMC statement\n",
    "def fetch_statement(url):\n",
    "    response = requests.get(url)\n",
    "    return response.text\n",
    "\n",
    "# URLs for the September and November 2023 FOMC statements\n",
    "september_url = \"https://www.federalreserve.gov/monetarypolicy/files/monetary20240918a1.pdf\"\n",
    "november_url = \"https://www.federalreserve.gov/monetarypolicy/files/monetary20241107a1.pdf\"\n",
    "\n",
    "# Fetch the content of both statements\n",
    "september_content = fetch_statement(september_url)\n",
    "november_content = fetch_statement(november_url)\n",
    "\n",
    "# Function to compare the two statements and highlight differences\n",
    "def compare_statements(doc1, doc2):\n",
    "    differ = difflib.Differ()\n",
    "    diff = differ.compare(doc1.splitlines(), doc2.splitlines())\n",
    "    \n",
    "    # Output the diff as a string\n",
    "    diff_result = \"\\n\".join(diff)\n",
    "    return diff_result\n",
    "\n",
    "# Get the differences between September and November statements\n",
    "differences = compare_statements(september_content, november_content)\n",
    "\n",
    "# Output the differences\n",
    "with open(\"fomc_diff_result.html\", \"w\", encoding=\"utf-8\") as output_file:\n",
    "    output_file.write(differences)\n",
    "\n",
    "print(\"Differences between September and November FOMC statements have been saved to 'fomc_diff_result.txt'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences between September and November FOMC statements have been saved to 'fomc_diff_result.txt'\n"
     ]
    }
   ],
   "source": [
    "import difflib\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "# Function to extract text from a PDF file\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    document = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(len(document)):\n",
    "        page = document.load_page(page_num)\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# Paths for the September and November 2023 FOMC statements\n",
    "september_pdf_path = \"monetary20240918a1.pdf\"\n",
    "november_pdf_path = \"monetary20241107a1.pdf\"\n",
    "\n",
    "# Extract text content from both PDF files\n",
    "september_content = extract_text_from_pdf(september_pdf_path)\n",
    "november_content = extract_text_from_pdf(november_pdf_path)\n",
    "\n",
    "# Function to compare the two statements and highlight differences\n",
    "def compare_statements(doc1, doc2):\n",
    "    differ = difflib.Differ()\n",
    "    diff = differ.compare(doc1.splitlines(), doc2.splitlines())\n",
    "    \n",
    "    # Output the diff as a string\n",
    "    diff_result = \"\\n\".join(diff)\n",
    "    return diff_result\n",
    "\n",
    "# Get the differences between September and November statements\n",
    "differences = compare_statements(september_content, november_content)\n",
    "\n",
    "# Output the differences\n",
    "with open(\"fomc_diff_result.html\", \"w\", encoding=\"utf-8\") as output_file:\n",
    "    output_file.write(differences)\n",
    "\n",
    "print(\"Differences between September and November FOMC statements have been saved to 'fomc_diff_result.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences between September and November FOMC statements have been saved to 'fomc_diff_result.html'\n"
     ]
    }
   ],
   "source": [
    "import difflib\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "# Function to extract text from a PDF file\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    document = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(len(document)):\n",
    "        page = document.load_page(page_num)\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# Paths for the September and November 2023 FOMC statements\n",
    "september_pdf_path = \"monetary20240918a1.pdf\"\n",
    "november_pdf_path = \"monetary20241107a1.pdf\"\n",
    "\n",
    "# Extract text content from both PDF files\n",
    "september_content = extract_text_from_pdf(september_pdf_path)\n",
    "november_content = extract_text_from_pdf(november_pdf_path)\n",
    "\n",
    "# Function to compare the two statements and highlight differences\n",
    "def compare_statements(doc1, doc2):\n",
    "    differ = difflib.HtmlDiff()\n",
    "    diff = differ.make_file(doc1.splitlines(), doc2.splitlines(), fromdesc='September 2023', todesc='November 2023')\n",
    "    return diff\n",
    "\n",
    "# Get the differences between September and November statements\n",
    "differences = compare_statements(september_content, november_content)\n",
    "\n",
    "# Output the differences\n",
    "with open(\"fomc_diff_result.html\", \"w\", encoding=\"utf-8\") as output_file:\n",
    "    output_file.write(differences)\n",
    "\n",
    "print(\"Differences between September and November FOMC statements have been saved to 'fomc_diff_result.html'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences between September and November FOMC statements have been saved to 'fomc_diff_result.html'\n"
     ]
    }
   ],
   "source": [
    "import difflib\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "# Function to extract text from a PDF file\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    document = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(len(document)):\n",
    "        page = document.load_page(page_num)\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# Paths for the September and November 2023 FOMC statements\n",
    "september_pdf_path = \"monetary20240918a1.pdf\"\n",
    "november_pdf_path = \"monetary20241107a1.pdf\"\n",
    "\n",
    "# Extract text content from both PDF files\n",
    "september_content = extract_text_from_pdf(september_pdf_path)\n",
    "november_content = extract_text_from_pdf(november_pdf_path)\n",
    "\n",
    "# Function to compare the two statements and highlight differences\n",
    "def compare_statements(doc1, doc2):\n",
    "    differ = difflib.HtmlDiff()\n",
    "    diff = differ.make_file(doc1.splitlines(), doc2.splitlines(), fromdesc='September 2023', todesc='November 2023')\n",
    "    return diff\n",
    "\n",
    "# Get the differences between September and November statements\n",
    "differences = compare_statements(september_content, november_content)\n",
    "\n",
    "# Output the differences\n",
    "with open(\"fomc_diff_result.html\", \"w\", encoding=\"utf-8\") as output_file:\n",
    "    output_file.write(differences)\n",
    "\n",
    "print(\"Differences between September and November FOMC statements have been saved to 'fomc_diff_result.html'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.9-py3-none-any.whl (1.0 MB)\n",
      "     ---------------------------------------- 1.0/1.0 MB 1.6 MB/s eta 0:00:00\n",
      "Collecting langsmith<0.2.0,>=0.1.17\n",
      "  Downloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
      "     -------------------------------------- 311.8/311.8 kB 2.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages (from langchain) (4.0.2)\n",
      "Collecting langchain-core<0.4.0,>=0.3.21\n",
      "  Downloading langchain_core-0.3.21-py3-none-any.whl (409 kB)\n",
      "     -------------------------------------- 409.5/409.5 kB 2.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages (from langchain) (2.10.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages (from langchain) (2.28.1)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages (from langchain) (8.2.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages (from langchain) (2.0.15)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages (from langchain) (5.3.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages (from langchain) (3.8.3)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0\n",
      "  Using cached langchain_text_splitters-0.3.2-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Collecting packaging<25,>=23.2\n",
      "  Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (4.12.2)\n",
      "Collecting jsonpatch<2.0,>=1.33\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.9.15)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.0)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.14)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.4)\n",
      "Requirement already satisfied: anyio in c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Collecting jsonpointer>=1.9\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.0)\n",
      "Installing collected packages: packaging, jsonpointer, requests-toolbelt, jsonpatch, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 22.0\n",
      "    Uninstalling packaging-22.0:\n",
      "      Successfully uninstalled packaging-22.0\n",
      "Successfully installed jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.9 langchain-core-0.3.21 langchain-text-splitters-0.3.2 langsmith-0.1.147 packaging-24.2 requests-toolbelt-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages)\n",
      "  WARNING: The script langsmith.exe is installed in 'c:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script langchain-server.exe is installed in 'c:\\Users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.25.3 which is incompatible.\n",
      "mlflow 2.11.1 requires packaging<24, but you have packaging 24.2 which is incompatible.\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ollama'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-01a9f2ddeae7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mollama\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mquestion_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"What is 2+2?\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mans_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"2 + 2 equals 4. This is a basic arithmetic operation where you are \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ollama'"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "question_1 = \"What is 2+2?\"\n",
    "\n",
    "ans_1 = \"2 + 2 equals 4. This is a basic arithmetic operation where you are \" \\\n",
    "        \"adding the number 2 to another number 2, resulting in 4.\"\n",
    "\n",
    "question_2 = \"Add 3 onto the last answer. What is it now?\"\n",
    "\n",
    "response = ollama.chat(\n",
    "    model=\"phi3\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": question_1},\n",
    "        {\"role\": \"assistant\", \"content\": ans_1},\n",
    "        {\"role\": \"user\", \"content\": question_2}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response[\"message\"][\"role\"])\n",
    "print(response[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement ollama (from versions: none)\n",
      "ERROR: No matching distribution found for ollama\n"
     ]
    }
   ],
   "source": [
    "pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant\n",
      "Sure! Here's an implementation of the Fibonacci sequence using recursion:\n",
      "\n",
      "```python\n",
      "def fibonacci(n):\n",
      "    if n <= 1:\n",
      "        return n\n",
      "    else:\n",
      "        return (fibonacci(n-1) + fibonacci(n-2))\n",
      "    \n",
      "print(fibonacci(7))  # Output: 13\n",
      "```\n",
      "\n",
      "In this example, the base case is when `n` is less than or equal to 1. The recursive case involves calling the function with `n-1` and `n-2`, which will eventually lead back to one of the base cases for each call stack frame created during recursion. While using recursion can make code look cleaner, it's important to be aware that this implementation has an exponential time complexity due to overlapping subproblems in memoization is needed or bottom up approach with tabulation method should be used instead as shown below:\n",
      "\n",
      "```python\n",
      "def fibonacci_mem(n):\n",
      "    dp = [0, 1] + [None] * (n-1)\n",
      "    \n",
      "    def helper(i):\n",
      "        if dp[i] is None:\n",
      "            dp[i] = helper(i-1) + helper(i-2)\n",
      "        return dp[i]\n",
      "        \n",
      "    return helper(n)  # n in the memoization cache here, not a base case. Hence no need for if...else condition anymore.  \n",
      "\n",
      "print(fibonacci_mem(7))  # Output: 13    \n",
      "```\n",
      "Here we used dynamic programming and avoided recursion altogether which can be helpful when dealing with larger inputs or problems that don't lend themselves to recursive solutions easily like this one, however it loses the elegance of code from before.\n",
      "\n",
      "Another important aspect is tail recursion where instead using multiple call stack frames as seen in previous examples we only have a single frame and then continuously reduce our input by decreasing `n` until reaching base case: \n",
      "```python\n",
      "def fibonacci_tail(n, prev=0, curr=1):\n",
      "    if n == 0 or n==1:   #base cases here which will terminate the recursive calls without calling itself again. Hence we get O(N) time and space complexity as only single call stack frame is being used throughout all these operations.    \n",
      "        return prev\n",
      "        \n",
      "    next = curr + fibonacci_tail(n-1,curr=curr+prev,prev=prev) #recursive calls here where the results of previous function invocations are stored and reused in each successive call until n becomes 0 which will terminate this process.    \n",
      "                                           \n",
      "    return next\n",
      "print(fibonacci_tail(7))  # Output: 13  \n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "# Define the initial prompt\n",
    "initial_prompt = \"You are a helpful assistant. Your task is to explain the concept of recursion in programming. Please provide a detailed explanation with examples. Make sure to cover the following points:\\n1. What is recursion?\\n2. How does recursion work?\\n3. Provide a simple example of a recursive function.\\n4. Explain the base case and recursive case.\\n5. Discuss the advantages and disadvantages of using recursion.\"\n",
    "\n",
    "# Define the follow-up question\n",
    "follow_up_question = \"Can you provide a more complex example of recursion, such as the Fibonacci sequence?\"\n",
    "\n",
    "# Generate the response using the ollama library\n",
    "response = ollama.chat(\n",
    "    model=\"phi3\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": initial_prompt},\n",
    "        {\"role\": \"assistant\", \"content\": \"Recursion is a programming technique where a function calls itself in order to solve a problem. It works by breaking down a problem into smaller, more manageable sub-problems. Here's a simple example of a recursive function that calculates the factorial of a number:\\n\\n```python\\ndef factorial(n):\\n    if n == 1:\\n        return 1\\n    else:\\n        return n * factorial(n-1)\\n\\nprint(factorial(5))  # Output: 120\\n```\\n\\nIn this example, the base case is when `n` is 1, and the recursive case is when the function calls itself with `n-1`. The advantages of using recursion include simpler code and easier problem-solving for certain types of problems. However, recursion can also lead to higher memory usage and slower performance if not used carefully.\"},\n",
    "        {\"role\": \"user\", \"content\": follow_up_question}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response[\"message\"][\"role\"])\n",
    "print(response[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38ad18b2270547b385dfdd094bf77c4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0/41 [00:00<?, ?files/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66a37daa98134e6595921423e1e77f72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00041.parquet:   0%|          | 0.00/1.04G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4c7457ba9f4449eaaa44fd723e1e064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00001-of-00041.parquet:   0%|          | 0.00/705M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18c771598c9c46e3bb96bb2b4a951e70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00002-of-00041.parquet:   0%|          | 0.00/558M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e65751143a4cc5a6373acf3a8137f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00003-of-00041.parquet:   0%|          | 0.00/491M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1de3fedffd0433ea04fc1f8a264f606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00004-of-00041.parquet:   0%|          | 0.00/431M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2b260717487435885faf858f21f63ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00005-of-00041.parquet:   0%|          | 0.00/391M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a122e7cc2ead4a97a820568de1de1acf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00006-of-00041.parquet:   0%|          | 0.00/366M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "966640cc87014a3fa6b3e788519209dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00007-of-00041.parquet:   0%|          | 0.00/326M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d97e0450ce7a45e8b2d26bdc042d82c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00008-of-00041.parquet:   0%|          | 0.00/329M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f2855f59b5f480d9984baddffb3fb4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00009-of-00041.parquet:   0%|          | 0.00/312M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7d844deba394e0fba3d864237b461b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00010-of-00041.parquet:   0%|          | 0.00/267M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "027b58352622467989a067945d5a3f8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00011-of-00041.parquet:   0%|          | 0.00/247M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b27c6b7ac386449b8221b05a368aad21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00012-of-00041.parquet:   0%|          | 0.00/229M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5d1afbd25d0413a800fd0c290b93292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00013-of-00041.parquet:   0%|          | 0.00/248M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faf9afa4e5bb412caef33888da3b4e9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00014-of-00041.parquet:   0%|          | 0.00/222M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ffe8cfd63c747b98f3b3e140bac3514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00015-of-00041.parquet:   0%|          | 0.00/236M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "845fe670e47a4dc7a9a82fbe62cd8716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00016-of-00041.parquet:   0%|          | 0.00/215M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10c8c460133248ea886b8f70fde4d148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00017-of-00041.parquet:   0%|          | 0.00/229M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e19988c68da847ff81ef8b54f1d9ce30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00018-of-00041.parquet:   0%|          | 0.00/241M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4055050e32bc4d818ad90ad3547ab6c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00019-of-00041.parquet:   0%|          | 0.00/228M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e901f0b39bc9418ea3a2b279bc73de90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00020-of-00041.parquet:   0%|          | 0.00/214M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "207b9361e55c40d9b4107079d7bf5ecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00021-of-00041.parquet:   0%|          | 0.00/255M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc19956fe7e4c88ae80641d8f6d4b24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00022-of-00041.parquet:   0%|          | 0.00/226M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7480d8921cf149a58356527e1261697b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00023-of-00041.parquet:   0%|          | 0.00/226M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8977cd1df3af42f0a26247de645efdad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00024-of-00041.parquet:   0%|          | 0.00/192M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc2557de2b98473bb0a18f4fc4e638ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00025-of-00041.parquet:   0%|          | 0.00/218M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ccde0afd94b4965a222e932d8b6a55a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00026-of-00041.parquet:   0%|          | 0.00/212M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f249678fe2bf4a7fb84c4486d448f708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00027-of-00041.parquet:   0%|          | 0.00/206M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b802d9a3a1447ba9f6cc59ca7803c10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00028-of-00041.parquet:   0%|          | 0.00/199M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a9cc689dc9542e08785c6158d13aaf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00029-of-00041.parquet:   0%|          | 0.00/219M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6034173b97274e76b31398e0d08c7d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00030-of-00041.parquet:   0%|          | 0.00/214M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f77fa499b70f4a659f8c28488cc742b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00031-of-00041.parquet:   0%|          | 0.00/216M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bedcde16f848480393e48c73e69afb4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00032-of-00041.parquet:   0%|          | 0.00/200M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a3bc910fe8b4d728c0b62bed3af04b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00033-of-00041.parquet:   0%|          | 0.00/203M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "639e01edb68d4383855732373ed99cac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00034-of-00041.parquet:   0%|          | 0.00/201M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fdee83aa71b4acb93ad9379fe962c7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00035-of-00041.parquet:   0%|          | 0.00/192M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba77c8e9ff14232ab8f3cc89947e404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00036-of-00041.parquet:   0%|          | 0.00/199M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d391f8eb1a80474e9f1c8fa27131c121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00037-of-00041.parquet:   0%|          | 0.00/195M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d23b9dbf6034aa2b0d2d5d387717066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00038-of-00041.parquet:   0%|          | 0.00/203M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef007df616a84a8d8d84b193979c7300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00039-of-00041.parquet:   0%|          | 0.00/192M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ca0b8595e7f4fd9a2cf14d33c591f49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00040-of-00041.parquet:   0%|          | 0.00/185M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bf0ce53e20f4f59b7575089f9635340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/6458670 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'page_content'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m text_splitter \u001b[38;5;241m=\u001b[39m RecursiveCharacterTextSplitter(chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, chunk_overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n\u001b[0;32m     14\u001b[0m documents \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: doc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]} \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m dataset]\n\u001b[1;32m---> 15\u001b[0m splits \u001b[38;5;241m=\u001b[39m \u001b[43mtext_splitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Generate embeddings for the text chunks\u001b[39;00m\n\u001b[0;32m     18\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence-transformers/all-MiniLM-L6-v2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\johnn\\anaconda3\\envs\\ptoch_2023\\lib\\site-packages\\langchain_text_splitters\\base.py:94\u001b[0m, in \u001b[0;36mTextSplitter.split_documents\u001b[1;34m(self, documents)\u001b[0m\n\u001b[0;32m     92\u001b[0m texts, metadatas \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents:\n\u001b[1;32m---> 94\u001b[0m     texts\u001b[38;5;241m.\u001b[39mappend(\u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_content\u001b[49m)\n\u001b[0;32m     95\u001b[0m     metadatas\u001b[38;5;241m.\u001b[39mappend(doc\u001b[38;5;241m.\u001b[39mmetadata)\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_documents(texts, metadatas\u001b[38;5;241m=\u001b[39mmetadatas)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'page_content'"
     ]
    }
   ],
   "source": [
    "# from datasets import load_dataset\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# from langchain.embeddings import HuggingFaceEmbeddings\n",
    "# from langchain.vectorstores import Chroma\n",
    "# from transformers import RagTokenizer, RagRetriever, RagSequenceForGeneration\n",
    "# from datasets import load_dataset\n",
    "# import torch\n",
    "\n",
    "# # Load Wikipedia dataset\n",
    "# dataset = load_dataset(\"wikipedia\", \"20220301.en\", split=\"train[:1%]\", trust_remote_code=True)  # Load a small subset for demonstration\n",
    "\n",
    "# # Split the data into chunks\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "# documents = [{\"text\": doc[\"text\"]} for doc in dataset]\n",
    "# splits = text_splitter.split_documents(documents)\n",
    "\n",
    "# # Generate embeddings for the text chunks\n",
    "# model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "# embedding = HuggingFaceEmbeddings(model_name=model_name, model_kwargs={'device': 'cpu'})\n",
    "\n",
    "# # Store the embeddings in a vector store\n",
    "# persist_directory = 'wiki_db'\n",
    "# vectordb = Chroma.from_documents(documents=splits, embedding=embedding, persist_directory=persist_directory)\n",
    "\n",
    "# # Load RAG model and tokenizer\n",
    "# rag_model_name = \"facebook/rag-sequence-nq\"\n",
    "# tokenizer = RagTokenizer.from_pretrained(rag_model_name)\n",
    "# retriever = RagRetriever.from_pretrained(rag_model_name, index_name=\"exact\", use_dummy_dataset=True)\n",
    "# model = RagSequenceForGeneration.from_pretrained(rag_model_name, retriever=retriever).to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "# # Define a function to generate responses using RAG\n",
    "# def generate_response(prompt):\n",
    "#     input_ids = tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"]\n",
    "#     generated_ids = model.generate(input_ids, num_beams=2, max_length=100, early_stopping=True)\n",
    "#     generated_text = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "#     return generated_text\n",
    "\n",
    "# # Example usage\n",
    "# prompt = \"Explain the concept of recursion in programming.\"\n",
    "# response = generate_response(prompt)\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.schema import Document\n",
    "# documents = [Document(page_content=doc[\"text\"]) for doc in dataset]\n",
    "# splits = text_splitter.split_documents(documents)\n",
    "\n",
    "# # Generate embeddings for the text chunks\n",
    "# model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "# embedding = HuggingFaceEmbeddings(model_name=model_name, model_kwargs={'device': 'cpu'})\n",
    "\n",
    "# # Store the embeddings in a vector store\n",
    "# persist_directory = 'wiki_db'\n",
    "# vectordb = Chroma.from_documents(documents=splits, embedding=embedding, persist_directory=persist_directory)\n",
    "\n",
    "# # Load RAG model and tokenizer\n",
    "# rag_model_name = \"facebook/rag-sequence-nq\"\n",
    "# tokenizer = RagTokenizer.from_pretrained(rag_model_name)\n",
    "# retriever = RagRetriever.from_pretrained(rag_model_name, index_name=\"exact\", use_dummy_dataset=True)\n",
    "# model = RagSequenceForGeneration.from_pretrained(rag_model_name, retriever=retriever).to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "# # Define a function to generate responses using RAG\n",
    "# def generate_response(prompt):\n",
    "#     input_ids = tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"]\n",
    "#     generated_ids = model.generate(input_ids, num_beams=2, max_length=100, early_stopping=True)\n",
    "#     generated_text = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "#     return generated_text\n",
    "\n",
    "# # Example usage\n",
    "# prompt = \"Explain the concept of recursion in programming.\"\n",
    "# response = generate_response(prompt)\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement google-generativeai (from versions: none)\n",
      "ERROR: No matching distribution found for google-generativeai\n"
     ]
    }
   ],
   "source": [
    "pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fetch_financial_report_api import FinancialReportAPI\n",
    "\n",
    "api = FinancialReportAPI()\n",
    "reports = api.get_tsmc_reports(start_year=2020, end_year=2025)\n",
    "for report in reports:\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromedriver_autoinstaller\n",
      "  Downloading chromedriver_autoinstaller-0.6.4-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: packaging>=23.1 in c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages (from chromedriver_autoinstaller) (24.2)\n",
      "Installing collected packages: chromedriver_autoinstaller\n",
      "Successfully installed chromedriver_autoinstaller-0.6.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\johnn\\anaconda3\\envs\\tf_2.3_py_3.7\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install chromedriver_autoinstaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "發生錯誤：Message: invalid element state\n",
      "  (Session info: chrome=136.0.7103.114)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00F2FC03+61635]\n",
      "\tGetHandleVerifier [0x00F2FC44+61700]\n",
      "\t(No symbol) [0x00D5044E]\n",
      "\t(No symbol) [0x00D8FFE4]\n",
      "\t(No symbol) [0x00DBD29C]\n",
      "\t(No symbol) [0x00D8E034]\n",
      "\t(No symbol) [0x00DBD514]\n",
      "\t(No symbol) [0x00DDE61B]\n",
      "\t(No symbol) [0x00DBD096]\n",
      "\t(No symbol) [0x00D8C840]\n",
      "\t(No symbol) [0x00D8D6A4]\n",
      "\tGetHandleVerifier [0x011B4523+2701795]\n",
      "\tGetHandleVerifier [0x011AFCA6+2683238]\n",
      "\tGetHandleVerifier [0x011CA9EE+2793134]\n",
      "\tGetHandleVerifier [0x00F468C5+155013]\n",
      "\tGetHandleVerifier [0x00F4CFAD+181357]\n",
      "\tGetHandleVerifier [0x00F37458+92440]\n",
      "\tGetHandleVerifier [0x00F37600+92864]\n",
      "\tGetHandleVerifier [0x00F21FF0+5296]\n",
      "\tBaseThreadInitThunk [0x75C05D49+25]\n",
      "\tRtlInitializeExceptionChain [0x77C0D03B+107]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x77C0CFC1+561]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# selenium_financial_scraper.py\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import chromedriver_autoinstaller\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import time\n",
    "\n",
    "\n",
    "def init_driver(headless: bool = True):\n",
    "    options = Options()\n",
    "    if headless:\n",
    "        options.add_argument(\"--headless\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    # Automatically download and install the correct version of chromedriver\n",
    "    chromedriver_autoinstaller.install()\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    return driver\n",
    "\n",
    "\n",
    "def fetch_tsmc_financials_from_mops():\n",
    "    url = \"https://doc.twse.com.tw/server-java/t57sb01?step=1&colorchg=1&co_id=2330&year=114&mtype=A\"\n",
    "    driver = init_driver()\n",
    "    driver.get(url)\n",
    "\n",
    "    try:\n",
    "        # 選擇公司代號（2330 是台積電）\n",
    "        stock_input = WebDriverWait(driver, 50).until(\n",
    "            EC.presence_of_element_located((By.NAME, \"co_id\"))\n",
    "        )\n",
    "        stock_input.clear()\n",
    "        stock_input.send_keys(\"2330\")\n",
    "\n",
    "        # 選擇年度與季度\n",
    "        year_input = WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.NAME, \"year\"))\n",
    "        )\n",
    "        year_input.clear()\n",
    "        year_input.send_keys(\"112\")  # 民國年：2023 = 112\n",
    "\n",
    "        season_select = WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.NAME, \"season\"))\n",
    "        )\n",
    "        season_select.send_keys(\"01\")  # 第一季\n",
    "\n",
    "        # 提交查詢\n",
    "        submit_button = WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.XPATH, '//input[@value=\"查詢\"]'))\n",
    "        )\n",
    "        submit_button.click()\n",
    "\n",
    "        # 等待結果表格載入\n",
    "        WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"hasBorder\"))\n",
    "        )\n",
    "\n",
    "        # 擷取表格文字\n",
    "        tables = driver.find_elements(By.CLASS_NAME, \"hasBorder\")\n",
    "        print(\"成功擷取財報，共\", len(tables), \"個表格\")\n",
    "\n",
    "        financial_data = []\n",
    "        for table in tables:\n",
    "            financial_data.append(table.text)\n",
    "\n",
    "        return financial_data\n",
    "\n",
    "    except TimeoutException as e:\n",
    "        print(\"TimeoutException occurred:\", e)\n",
    "        driver.save_screenshot(\"timeout_screenshot.png\")  # 儲存截圖\n",
    "        with open(\"page_source.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(driver.page_source)  # 儲存 HTML\n",
    "        raise\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        data = fetch_tsmc_financials_from_mops()\n",
    "        for idx, section in enumerate(data):\n",
    "            print(f\"\\n------ 表格 {idx+1} ------\\n\")\n",
    "            print(section)\n",
    "    except Exception as e:\n",
    "        print(f\"發生錯誤：{e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_2.3_py_3.7",
   "language": "python",
   "name": "tf_2.3_py_3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
