#!/usr/bin/env python3
"""
ä½¿ç”¨ tasks.py ä¸­çš„è¶…åƒæ•¸å„ªåŒ–åŠŸèƒ½è¨“ç·´æ¨¡å‹
é€™å€‹è…³æœ¬æœƒç›´æ¥èª¿ç”¨ tasks.py ä¸­çš„å‡½æ•¸ï¼Œè€Œä¸éœ€è¦ Celery æœå‹™
"""

import os
import sys
import pandas as pd
import logging
from datetime import datetime
import uuid

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)

# é…ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('hyperopt_training.log')
    ]
)

logger = logging.getLogger(__name__)


def run_hyperopt_training():
    """åŸ·è¡Œè¶…åƒæ•¸å„ªåŒ–è¨“ç·´"""
    try:
        # è¼‰å…¥è¨“ç·´è³‡æ–™
        logger.info("ğŸ”„ æ­£åœ¨è¼‰å…¥è¨“ç·´è³‡æ–™...")
        train_data_path = "data/raw/train.csv"
        
        if not os.path.exists(train_data_path):
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°è¨“ç·´è³‡æ–™æª”æ¡ˆ: {train_data_path}")
        
        df = pd.read_csv(train_data_path)
        logger.info(f"âœ… æˆåŠŸè¼‰å…¥ {len(df)} ç­†è¨“ç·´è³‡æ–™")
        logger.info(f"ğŸ“Š è³‡æ–™å½¢ç‹€: {df.shape}")
        logger.info(f"ğŸ“‹ æ¬„ä½åç¨±: {list(df.columns)}")
        
        # æª¢æŸ¥ç›®æ¨™è®Šæ•¸åˆ†å¸ƒ
        target_col = 'loan_status'
        if target_col in df.columns:
            target_dist = df[target_col].value_counts()
            logger.info("ğŸ¯ ç›®æ¨™è®Šæ•¸åˆ†å¸ƒ:")
            for label, count in target_dist.items():
                logger.info(f"  {label}: {count} ({count/len(df)*100:.1f}%)")
        
        # ç”Ÿæˆå”¯ä¸€çš„ä»»å‹™ ID
        job_id = (f"hyperopt_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                  f"_{str(uuid.uuid4())[:8]}")
        logger.info(f"ğŸ†” ä»»å‹™ ID: {job_id}")
        
        # å»ºç«‹ä»»å‹™ç‹€æ…‹è¿½è¹¤å­—å…¸
        training_jobs = {
            job_id: {
                "status": "INITIALIZED",
                "created_at": datetime.now().isoformat(),
                "progress": 0,
                "message": "ä»»å‹™åˆå§‹åŒ–..."
            }
        }
        
        # ç›´æ¥åŒ¯å…¥ä¸¦èª¿ç”¨è¶…åƒæ•¸å„ªåŒ–ä»»å‹™
        logger.info("ğŸš€ é–‹å§‹åŸ·è¡Œè¶…åƒæ•¸å„ªåŒ–è¨“ç·´...")
        
        # ç›´æ¥åŒ¯å…¥ tasks æ¨¡çµ„ä¸­çš„è¨“ç·´å‡½æ•¸
        from app.tasks import train_model_task
        
        # åŸ·è¡Œå¸¶æœ‰è¶…åƒæ•¸å„ªåŒ–çš„æ¨¡å‹è¨“ç·´
        result = train_model_task(
            job_id=job_id,
            df=df,
            use_hyperopt=True,  # å•Ÿç”¨è¶…åƒæ•¸å„ªåŒ–
            cv_folds=5,
            training_jobs=training_jobs
        )
        
        # æª¢æŸ¥è¨“ç·´çµæœ
        if training_jobs[job_id]["status"] == "SUCCESS":
            logger.info("ğŸ‰ è¶…åƒæ•¸å„ªåŒ–è¨“ç·´æˆåŠŸå®Œæˆï¼")
            
            result_info = training_jobs[job_id].get("result", {})
            
            if result_info:
                logger.info("ğŸ“Š è¨“ç·´çµæœ:")
                model_id = result_info.get('model_id', 'N/A')
                logger.info(f"  ğŸ†” æ¨¡å‹ ID: {model_id}")
                
                cv_scores = result_info.get('cv_scores', 'N/A')
                logger.info(f"  ï¿½ äº¤å‰é©—è­‰åˆ†æ•¸: {cv_scores}")
                
                feature_count = result_info.get('feature_count', 'N/A')
                logger.info(f"  ï¿½ ç‰¹å¾µæ•¸é‡: {feature_count}")
                
                training_samples = result_info.get('training_samples', 'N/A')
                logger.info(f"  ğŸ”¢ è¨“ç·´æ¨£æœ¬æ•¸: {training_samples}")
                
                hyperopt_used = result_info.get('hyperopt_used', 'N/A')
                logger.info(f"  âš™ï¸ ä½¿ç”¨è¶…åƒæ•¸å„ªåŒ–: {hyperopt_used}")
                
                completed_at = result_info.get('completed_at', 'N/A')
                logger.info(f"  ğŸ“… å®Œæˆæ™‚é–“: {completed_at}")
                
                # å¦‚æœæœ‰å„ªåŒ–åƒæ•¸ï¼Œé¡¯ç¤ºæœ€ä½³åƒæ•¸
                optimized_params = result_info.get('optimized_params')
                if optimized_params:
                    logger.info("ğŸ¯ æœ€ä½³è¶…åƒæ•¸:")
                    for key, value in optimized_params.items():
                        logger.info(f"  {key}: {value}")
            
            logger.info("ğŸ’¾ æ¨¡å‹å·²ä¿å­˜åˆ° models/ ç›®éŒ„")
            
        else:
            logger.error("âŒ è¶…åƒæ•¸å„ªåŒ–è¨“ç·´å¤±æ•—")
            error_msg = training_jobs[job_id].get('message', 'Unknown error')
            logger.error(f"éŒ¯èª¤è¨Šæ¯: {error_msg}")
            if 'error' in training_jobs[job_id]:
                logger.error(f"è©³ç´°éŒ¯èª¤: {training_jobs[job_id]['error']}")
        
        return result
        
    except Exception as e:
        logger.error(f"âŒ åŸ·è¡Œéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        logger.exception("è©³ç´°éŒ¯èª¤ä¿¡æ¯:")
        return None


def check_dependencies():
    """æª¢æŸ¥å¿…è¦çš„ä¾è³´"""
    try:
        logger.info("ğŸ” æ­£åœ¨æª¢æŸ¥ä¾è³´å¥—ä»¶...")
        
        # æª¢æŸ¥åŸºæœ¬å¥—ä»¶
        import pandas as pd
        import numpy as np
        import sklearn
        logger.info(f"âœ… pandas: {pd.__version__}")
        logger.info(f"âœ… numpy: {np.__version__}")
        logger.info(f"âœ… scikit-learn: {sklearn.__version__}")
        
        # æª¢æŸ¥æ©Ÿå™¨å­¸ç¿’å¥—ä»¶
        try:
            import lightgbm as lgb
            logger.info(f"âœ… LightGBM: {lgb.__version__}")
        except ImportError:
            logger.warning("âš ï¸ LightGBM æœªå®‰è£")
        
        try:
            import xgboost as xgb
            logger.info(f"âœ… XGBoost: {xgb.__version__}")
        except ImportError:
            logger.warning("âš ï¸ XGBoost æœªå®‰è£")
        
        # æª¢æŸ¥è¶…åƒæ•¸å„ªåŒ–å¥—ä»¶
        try:
            import hyperopt
            logger.info(f"âœ… HyperOpt: {hyperopt.__version__}")
        except ImportError:
            logger.warning("âš ï¸ HyperOpt æœªå®‰è£ï¼Œå°‡ç„¡æ³•é€²è¡Œè¶…åƒæ•¸å„ªåŒ–")
        
        # æª¢æŸ¥å°ˆæ¡ˆæ¨¡çµ„
        try:
            from app.model import StackingModel  # noqa: F401
            from app.preprocessing import AdvancedDataPreprocessor  # noqa: F401
            from app.utils import save_model, generate_model_id  # noqa: F401
            logger.info("âœ… å°ˆæ¡ˆæ¨¡çµ„è¼‰å…¥æˆåŠŸ")
        except ImportError as e:
            logger.error(f"âŒ å°ˆæ¡ˆæ¨¡çµ„è¼‰å…¥å¤±æ•—: {e}")
            return False
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ ä¾è³´æª¢æŸ¥å¤±æ•—: {e}")
        return False


if __name__ == "__main__":
    logger.info("ğŸš€ é–‹å§‹è¶…åƒæ•¸å„ªåŒ–è¨“ç·´ç¨‹åº")
    logger.info("=" * 60)
    
    # æª¢æŸ¥ä¾è³´
    if not check_dependencies():
        logger.error("âŒ ä¾è³´æª¢æŸ¥å¤±æ•—ï¼Œç¨‹åºçµ‚æ­¢")
        sys.exit(1)
    
    logger.info("=" * 60)
    
    # åŸ·è¡Œè¨“ç·´
    result = run_hyperopt_training()
    
    logger.info("=" * 60)
    
    if result is not None:
        logger.info("ğŸ‰ ç¨‹åºåŸ·è¡Œå®Œæˆ")
    else:
        logger.error("âŒ ç¨‹åºåŸ·è¡Œå¤±æ•—")
        sys.exit(1)
