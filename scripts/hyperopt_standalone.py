#!/usr/bin/env python3
"""
æœ¬åœ°è¶…åƒæ•¸å„ªåŒ–è…³æœ¬
ç›´æ¥èª¿ç”¨ tasks.py ä¸­çš„è¶…åƒæ•¸å„ªåŒ–å‡½æ•¸ï¼Œç„¡éœ€ Celery æœå‹™
"""

import os
import sys
import pandas as pd
import logging
from datetime import datetime
import uuid

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)

# é…ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('hyperopt_training.log')
    ]
)

logger = logging.getLogger(__name__)


def run_standalone_hyperopt():
    """åŸ·è¡Œç¨ç«‹çš„è¶…åƒæ•¸å„ªåŒ–ï¼ˆä¸éœ€è¦ Celeryï¼‰"""
    try:
        # è¼‰å…¥è¨“ç·´è³‡æ–™
        logger.info("ğŸ”„ æ­£åœ¨è¼‰å…¥è¨“ç·´è³‡æ–™...")
        train_data_path = "data/raw/train.csv"
        
        if not os.path.exists(train_data_path):
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°è¨“ç·´è³‡æ–™æª”æ¡ˆ: {train_data_path}")
        
        df = pd.read_csv(train_data_path)
        logger.info(f"âœ… æˆåŠŸè¼‰å…¥ {len(df)} ç­†è¨“ç·´è³‡æ–™")
        logger.info(f"ğŸ“Š è³‡æ–™å½¢ç‹€: {df.shape}")
        logger.info(f"ğŸ“‹ æ¬„ä½åç¨±: {list(df.columns)}")
        
        # æª¢æŸ¥ç›®æ¨™è®Šæ•¸åˆ†å¸ƒ
        target_col = 'loan_status'
        if target_col in df.columns:
            target_dist = df[target_col].value_counts()
            logger.info("ğŸ¯ ç›®æ¨™è®Šæ•¸åˆ†å¸ƒ:")
            for label, count in target_dist.items():
                pct = count/len(df)*100
                logger.info(f"  {label}: {count} ({pct:.1f}%)")
        
        # æ•¸æ“šé è™•ç†
        logger.info("ğŸ”§ é–‹å§‹æ•¸æ“šé è™•ç†...")
        from app.preprocessing import AdvancedDataPreprocessor
        
        preprocessor = AdvancedDataPreprocessor(create_interactions=True)
        X, y = preprocessor.fit_transform_with_target(df)
        
        logger.info(f"âœ… æ•¸æ“šé è™•ç†å®Œæˆï¼Œç‰¹å¾µæ•¸é‡: {X.shape[1]}")
        logger.info(f"ğŸ“Š ç‰¹å¾µåç¨±: {list(X.columns)}")
        
        # ç”Ÿæˆå”¯ä¸€çš„ä»»å‹™ ID
        job_id = (f"hyperopt_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                  f"_{str(uuid.uuid4())[:8]}")
        logger.info(f"ğŸ†” ä»»å‹™ ID: {job_id}")
        
        # å»ºç«‹ä»»å‹™ç‹€æ…‹è¿½è¹¤å­—å…¸
        training_jobs = {
            job_id: {
                "status": "INITIALIZED",
                "created_at": datetime.now().isoformat(),
                "progress": 0,
                "message": "ä»»å‹™åˆå§‹åŒ–..."
            }
        }
        
        # ç›´æ¥èª¿ç”¨è¶…åƒæ•¸å„ªåŒ–å‡½æ•¸ï¼ˆä¸é€šé Celeryï¼‰
        logger.info("ğŸš€ é–‹å§‹è¶…åƒæ•¸å„ªåŒ–...")
        from app.tasks import optimize_hyperparameters_task
        
        # ç›´æ¥èª¿ç”¨è¶…åƒæ•¸å„ªåŒ–ä»»å‹™
        optimization_result = optimize_hyperparameters_task(
            job_id=job_id,
            X=X,
            y=y,
            n_trials=30,  # æ¸›å°‘è©¦é©—æ¬¡æ•¸ä»¥åŠ å¿«é€Ÿåº¦
            training_jobs=training_jobs
        )
        
        # æª¢æŸ¥å„ªåŒ–çµæœ
        if optimization_result and 'best_params' in optimization_result:
            logger.info("ğŸ‰ è¶…åƒæ•¸å„ªåŒ–æˆåŠŸå®Œæˆï¼")
            logger.info("ğŸ“Š å„ªåŒ–çµæœ:")
            
            best_score = optimization_result.get('best_score', 0)
            logger.info(f"  ğŸ† æœ€ä½³ AUC åˆ†æ•¸: {best_score:.4f}")
            
            n_trials = optimization_result.get('n_trials', 0)
            logger.info(f"  ğŸ”¬ ç¸½è©¦é©—æ¬¡æ•¸: {n_trials}")
            
            method = optimization_result.get('optimization_method', 'N/A')
            logger.info(f"  âš™ï¸ å„ªåŒ–æ–¹æ³•: {method}")
            
            # é¡¯ç¤ºæœ€ä½³åƒæ•¸
            best_params = optimization_result['best_params']
            logger.info("ğŸ¯ æœ€ä½³è¶…åƒæ•¸:")
            for key, value in best_params.items():
                logger.info(f"  {key}: {value}")
            
            # ç¾åœ¨ç”¨æœ€ä½³åƒæ•¸è¨“ç·´å®Œæ•´æ¨¡å‹
            logger.info("ğŸš€ ä½¿ç”¨æœ€ä½³åƒæ•¸è¨“ç·´å®Œæ•´æ¨¡å‹...")
            return train_final_model_with_best_params(
                df, best_params, preprocessor, job_id
            )
            
        else:
            logger.error("âŒ è¶…åƒæ•¸å„ªåŒ–å¤±æ•—")
            if training_jobs[job_id]["status"] == "FAILURE":
                error_msg = training_jobs[job_id].get("message", "Unknown error")
                logger.error(f"éŒ¯èª¤è¨Šæ¯: {error_msg}")
            return None
        
    except Exception as e:
        logger.error(f"âŒ åŸ·è¡Œéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        logger.exception("è©³ç´°éŒ¯èª¤ä¿¡æ¯:")
        return None


def train_final_model_with_best_params(df, best_params, preprocessor, job_id):
    """ä½¿ç”¨æœ€ä½³åƒæ•¸è¨“ç·´æœ€çµ‚æ¨¡å‹"""
    try:
        from app.model import StackingModel
        from app.utils import save_model, generate_model_id
        from sklearn.linear_model import LogisticRegression
        
        logger.info("ğŸ”§ é…ç½®æœ€çµ‚æ¨¡å‹...")
        
        # é è™•ç†æ•¸æ“š
        X, y = preprocessor.fit_transform_with_target(df)
        
        # å‰µå»º Stacking æ¨¡å‹
        stacking_model = StackingModel(cv_folds=5)
        
        # æ‡‰ç”¨æœ€ä½³è¶…åƒæ•¸
        logger.info("ğŸ¯ æ‡‰ç”¨æœ€ä½³è¶…åƒæ•¸...")
        
        # æ›´æ–° LightGBM åƒæ•¸
        lgb_updates = {}
        for key, value in best_params.items():
            if key.startswith('lgbm_'):
                param_name = key.replace('lgbm_', '')
                if param_name in ['n_estimators', 'num_leaves', 'max_depth',
                                  'min_child_samples']:
                    lgb_updates[param_name] = int(value)
                else:
                    lgb_updates[param_name] = value
        
        if lgb_updates:
            stacking_model.lgb_params.update(lgb_updates)
            logger.info(f"ğŸ“Š LightGBM åƒæ•¸å·²æ›´æ–°: {lgb_updates}")
        
        # æ›´æ–° XGBoost åƒæ•¸
        xgb_updates = {}
        for key, value in best_params.items():
            if key.startswith('xgb_'):
                param_name = key.replace('xgb_', '')
                if param_name in ['n_estimators', 'max_depth', 'min_child_weight']:
                    xgb_updates[param_name] = int(value)
                else:
                    xgb_updates[param_name] = value
        
        if xgb_updates:
            stacking_model.xgb_params.update(xgb_updates)
            logger.info(f"ğŸš€ XGBoost åƒæ•¸å·²æ›´æ–°: {xgb_updates}")
        
        # æ›´æ–° Meta Model
        if 'meta_C' in best_params:
            stacking_model.meta_model = LogisticRegression(
                C=best_params['meta_C'],
                solver=best_params.get('meta_solver', 'lbfgs'),
                random_state=42,
                max_iter=1000
            )
            meta_c = best_params['meta_C']
            logger.info(f"ğŸ¯ Meta Model åƒæ•¸å·²æ›´æ–°: C={meta_c}")
        
        # è¨“ç·´æ¨¡å‹
        logger.info("ğŸš€ é–‹å§‹è¨“ç·´æœ€çµ‚æ¨¡å‹...")
        stacking_model.fit(X, y)
        logger.info("âœ… æ¨¡å‹è¨“ç·´å®Œæˆ")
        
        # è©•ä¼°æ¨¡å‹
        logger.info("ğŸ“Š è©•ä¼°æ¨¡å‹æ€§èƒ½...")
        cv_scores = stacking_model.get_cv_scores()
        
        mean_score = cv_scores.get('mean_auc', 0)
        std_score = cv_scores.get('std_auc', 0)
        logger.info(f"ğŸ† äº¤å‰é©—è­‰ AUC: {mean_score:.4f} Â± {std_score:.4f}")
        
        # ä¿å­˜æ¨¡å‹
        logger.info("ğŸ’¾ ä¿å­˜æ¨¡å‹...")
        model_id = generate_model_id()
        save_model(stacking_model, preprocessor, model_id)
        
        logger.info(f"âœ… æ¨¡å‹å·²ä¿å­˜ï¼Œæ¨¡å‹ ID: {model_id}")
        
        # å‰µå»ºçµæœå­—å…¸
        result = {
            "model_id": model_id,
            "cv_scores": cv_scores,
            "best_params": best_params,
            "feature_count": X.shape[1],
            "training_samples": len(X),
            "hyperopt_used": True,
            "completed_at": datetime.now().isoformat(),
            "job_id": job_id
        }
        
        return result
        
    except Exception as e:
        logger.error(f"âŒ æœ€çµ‚æ¨¡å‹è¨“ç·´å¤±æ•—: {str(e)}")
        logger.exception("è©³ç´°éŒ¯èª¤ä¿¡æ¯:")
        return None


def check_dependencies():
    """æª¢æŸ¥å¿…è¦çš„ä¾è³´"""
    try:
        logger.info("ğŸ” æ­£åœ¨æª¢æŸ¥ä¾è³´å¥—ä»¶...")
        
        # æª¢æŸ¥åŸºæœ¬å¥—ä»¶
        import pandas as pd
        import numpy as np
        import sklearn
        logger.info(f"âœ… pandas: {pd.__version__}")
        logger.info(f"âœ… numpy: {np.__version__}")
        logger.info(f"âœ… scikit-learn: {sklearn.__version__}")
        
        # æª¢æŸ¥æ©Ÿå™¨å­¸ç¿’å¥—ä»¶
        try:
            import lightgbm as lgb
            logger.info(f"âœ… LightGBM: {lgb.__version__}")
        except ImportError:
            logger.error("âŒ LightGBM æœªå®‰è£ï¼Œè«‹å®‰è£: pip install lightgbm")
            return False
        
        try:
            import xgboost as xgb
            logger.info(f"âœ… XGBoost: {xgb.__version__}")
        except ImportError:
            logger.error("âŒ XGBoost æœªå®‰è£ï¼Œè«‹å®‰è£: pip install xgboost")
            return False
        
        # æª¢æŸ¥è¶…åƒæ•¸å„ªåŒ–å¥—ä»¶
        try:
            import hyperopt
            logger.info(f"âœ… HyperOpt: {hyperopt.__version__}")
        except ImportError:
            logger.error("âŒ HyperOpt æœªå®‰è£ï¼Œè«‹å®‰è£: pip install hyperopt")
            return False
        
        # æª¢æŸ¥å°ˆæ¡ˆæ¨¡çµ„
        try:
            from app.model import StackingModel  # noqa: F401
            from app.preprocessing import AdvancedDataPreprocessor  # noqa: F401
            from app.utils import save_model, generate_model_id  # noqa: F401
            logger.info("âœ… å°ˆæ¡ˆæ¨¡çµ„è¼‰å…¥æˆåŠŸ")
        except ImportError as e:
            logger.error(f"âŒ å°ˆæ¡ˆæ¨¡çµ„è¼‰å…¥å¤±æ•—: {e}")
            return False
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ ä¾è³´æª¢æŸ¥å¤±æ•—: {e}")
        return False


if __name__ == "__main__":
    logger.info("ğŸš€ é–‹å§‹ç¨ç«‹è¶…åƒæ•¸å„ªåŒ–ç¨‹åº")
    logger.info("=" * 60)
    
    # æª¢æŸ¥ä¾è³´
    if not check_dependencies():
        logger.error("âŒ ä¾è³´æª¢æŸ¥å¤±æ•—ï¼Œç¨‹åºçµ‚æ­¢")
        sys.exit(1)
    
    logger.info("=" * 60)
    
    # åŸ·è¡Œè¶…åƒæ•¸å„ªåŒ–
    result = run_standalone_hyperopt()
    
    logger.info("=" * 60)
    
    if result is not None:
        logger.info("ğŸ‰ ç¨‹åºåŸ·è¡Œå®Œæˆ")
        logger.info(f"ğŸ†” æ¨¡å‹ ID: {result.get('model_id', 'N/A')}")
        
        cv_scores = result.get('cv_scores', {})
        if cv_scores:
            mean_auc = cv_scores.get('mean_auc', 0)
            logger.info(f"ğŸ† æœ€çµ‚ AUC åˆ†æ•¸: {mean_auc:.4f}")
    else:
        logger.error("âŒ ç¨‹åºåŸ·è¡Œå¤±æ•—")
        sys.exit(1)
