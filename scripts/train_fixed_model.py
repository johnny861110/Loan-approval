#!/usr/bin/env python3
"""
ä½¿ç”¨å®Œæ•´è¨“ç·´æ•¸æ“šè¨“ç·´æ–°æ¨¡å‹ï¼Œä¸¦å›ºå®šç·¨ç¢¼å™¨
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from app.preprocessing import AdvancedDataPreprocessor
from app.model import StackingModel
from app.utils import save_model, generate_model_id
import logging

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def train_fixed_encoder_model():
    """ä½¿ç”¨å®Œæ•´æ•¸æ“šè¨“ç·´æ¨¡å‹ï¼Œä¸¦å›ºå®šç·¨ç¢¼å™¨"""
    
    print("ğŸš€ é–‹å§‹è¨“ç·´å›ºå®šç·¨ç¢¼å™¨æ¨¡å‹...")
    
    # 1. è®€å–å®Œæ•´è¨“ç·´æ•¸æ“š
    print("ğŸ“– è®€å–è¨“ç·´æ•¸æ“š...")
    data_path = "data/raw/train.csv"
    df = pd.read_csv(data_path)
    
    print(f"æ•¸æ“šå½¢ç‹€: {df.shape}")
    print(f"æ¬„ä½: {list(df.columns)}")
    
    # æª¢æŸ¥æ•¸æ“š
    print("\næ•¸æ“šæ¦‚è¦½:")
    print(df.head())
    
    print("\næ•¸æ“šé¡å‹:")
    print(df.dtypes)
    
    print("\nç¼ºå¤±å€¼:")
    print(df.isnull().sum())
    
    # 2. æº–å‚™æ•¸æ“š
    print("\nğŸ”§ æº–å‚™æ•¸æ“š...")
    
    # åˆ†é›¢ç‰¹å¾µå’Œç›®æ¨™
    X = df.drop(['loan_status'], axis=1)  # åŒ…å« id
    y = df['loan_status']
    
    print(f"ç‰¹å¾µæ•¸æ“šå½¢ç‹€: {X.shape}")
    print(f"ç›®æ¨™æ•¸æ“šå½¢ç‹€: {y.shape}")
    print(f"é¡åˆ¥åˆ†å¸ƒ: {y.value_counts().to_dict()}")
    
    # 3. å‰µå»ºå’Œè¨“ç·´é è™•ç†å™¨
    print("\nğŸ› ï¸ å‰µå»ºé€²éšé è™•ç†å™¨...")
    preprocessor = AdvancedDataPreprocessor(create_interactions=True)
    
    # ä½¿ç”¨å®Œæ•´æ•¸æ“šæ“¬åˆé è™•ç†å™¨ï¼ˆåŒ…å«æ‰€æœ‰å¯èƒ½çš„é¡åˆ¥å€¼ï¼‰
    print("ğŸ¯ æ“¬åˆé è™•ç†å™¨åˆ°å®Œæ•´æ•¸æ“šé›†...")
    X_processed = preprocessor.fit_transform(X)
    
    print(f"é è™•ç†å¾Œç‰¹å¾µæ•¸é‡: {X_processed.shape[1]}")
    print("é è™•ç†å¾Œç‰¹å¾µåˆ—è¡¨:")
    feature_names = preprocessor.get_feature_names()
    for i, feature in enumerate(feature_names):
        print(f"  {i+1:2d}. {feature}")
    
    # 4. åˆ†å‰²æ•¸æ“š
    print("\nâœ‚ï¸ åˆ†å‰²è¨“ç·´å’Œæ¸¬è©¦æ•¸æ“š...")
    X_train, X_test, y_train, y_test = train_test_split(
        X_processed, y, 
        test_size=0.2, 
        random_state=42, 
        stratify=y
    )
    
    print(f"è¨“ç·´é›†å½¢ç‹€: {X_train.shape}")
    print(f"æ¸¬è©¦é›†å½¢ç‹€: {X_test.shape}")
    
    # 5. è¨“ç·´æ¨¡å‹
    print("\nğŸ¤– è¨“ç·´ Stacking æ¨¡å‹...")
    model = StackingModel(
        cv_folds=5,
        random_state=42
    )
    
    # è¨“ç·´æ¨¡å‹
    model.fit(X_train, y_train)
    
    # 6. æ¨¡å‹è©•ä¼°
    print("\nğŸ“Š è©•ä¼°æ¨¡å‹...")
    from sklearn.metrics import roc_auc_score, accuracy_score
    
    # é æ¸¬è¨“ç·´é›†
    train_proba = model.predict_proba(X_train)  # å·²ç¶“æ˜¯æ­£é¡æ¦‚ç‡
    train_pred = model.predict(X_train)
    train_auc = roc_auc_score(y_train, train_proba)
    train_acc = accuracy_score(y_train, train_pred)
    
    # é æ¸¬æ¸¬è©¦é›†
    test_proba = model.predict_proba(X_test)  # å·²ç¶“æ˜¯æ­£é¡æ¦‚ç‡
    test_pred = model.predict(X_test)
    test_auc = roc_auc_score(y_test, test_proba)
    test_acc = accuracy_score(y_test, test_pred)
    
    print(f"è¨“ç·´é›† AUC: {train_auc:.4f}, æº–ç¢ºç‡: {train_acc:.4f}")
    print(f"æ¸¬è©¦é›† AUC: {test_auc:.4f}, æº–ç¢ºç‡: {test_acc:.4f}")
    
    # 7. ä¿å­˜æ¨¡å‹
    print("\nğŸ’¾ ä¿å­˜æ¨¡å‹...")
    model_id = generate_model_id()
    model_path = save_model(model, preprocessor, model_id)
    
    print(f"âœ… æ¨¡å‹å·²ä¿å­˜: {model_id}")
    print(f"æ¨¡å‹è·¯å¾‘: {model_path}")
    print(f"ç‰¹å¾µæ•¸é‡: {len(feature_names)}")
    
    # 8. é©—è­‰ä¿å­˜çš„æ¨¡å‹
    print("\nğŸ” é©—è­‰ä¿å­˜çš„æ¨¡å‹...")
    from app.utils import load_model
    
    loaded_model_data = load_model(model_id)
    loaded_preprocessor = loaded_model_data['preprocessor']
    loaded_features = loaded_preprocessor.get_feature_names()
    
    print(f"è¼‰å…¥çš„æ¨¡å‹ç‰¹å¾µæ•¸é‡: {len(loaded_features)}")
    
    if len(loaded_features) == len(feature_names):
        print("âœ… ç‰¹å¾µæ•¸é‡åŒ¹é…ï¼")
    else:
        print(f"âŒ ç‰¹å¾µæ•¸é‡ä¸åŒ¹é…: é æœŸ {len(feature_names)}, å¯¦éš› {len(loaded_features)}")
    
    # 9. æ¸¬è©¦é æ¸¬
    print("\nğŸ§ª æ¸¬è©¦é æ¸¬åŠŸèƒ½...")
    
    # å‰µå»ºæ¸¬è©¦æ¨£æœ¬
    test_sample = {
        "id": 999999,
        "person_age": 35,
        "person_income": 60000,
        "person_home_ownership": "RENT",
        "person_emp_length": 5,
        "loan_intent": "PERSONAL", 
        "loan_grade": "B",
        "loan_amnt": 10000,
        "loan_int_rate": 15.5,
        "loan_percent_income": 0.25,
        "cb_person_default_on_file": "N",
        "cb_person_cred_hist_length": 5
    }
    
    test_df = pd.DataFrame([test_sample])
    print(f"æ¸¬è©¦æ¨£æœ¬: {test_df.shape}")
    
    # ä½¿ç”¨è¼‰å…¥çš„é è™•ç†å™¨è™•ç†
    test_processed = loaded_preprocessor.transform(test_df)
    print(f"è™•ç†å¾Œæ¸¬è©¦æ¨£æœ¬: {test_processed.shape}")
    
    # é€²è¡Œé æ¸¬
    loaded_model = loaded_model_data['model']
    prediction = loaded_model.predict_proba(test_processed)
    
    print(f"é æ¸¬æ¦‚ç‡: {prediction[0]}")
    print(f"é æ¸¬é¡åˆ¥: {loaded_model.predict(test_processed)[0]}")
    
    print(f"\nğŸ‰ è¨“ç·´å®Œæˆï¼æ–°æ¨¡å‹ ID: {model_id}")
    
    return model_id, model_path

if __name__ == "__main__":
    model_id, model_path = train_fixed_encoder_model()
